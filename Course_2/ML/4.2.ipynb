{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Площадь под графиком и управление порогом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Цель работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Научиться применять кривые PR и ROC для оценки моделей классификации, использовать их для выбора оптимального порога классификации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Содержание работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Сгенерируйте датасет для бинарной классификации, обучите на нем модель логистической регрессии и постройте для этой модели кривые ROC и PR.\n",
        "1. Вычислите для этой модели метрики площади под кривыми (ROC-AUC и PR-AUC).\n",
        "1. Обучите на том же датасете другую модель и сравните ее эффективность по кривым и по метрикам.\n",
        "1. Сгенерируйте датасет для бинарной классификации с большим дисбалансом классов, обучите на нам ту же модель и постройте кривые.\n",
        "1. Используйте данные, вычисленные для построения кривых для нахождения оптимального значения порога модели. Постройте матрицу классификации для модели с порогом по умолчанию и с лучшим порогом. Сравните результаты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Методические указания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Начнем с получение датасета для бинарной классификации. Воспользуемся самым простым вариантом - сгенерируем его:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Разделим выборку на обучающую и тестовую. В данном случае нам не очень важны будут показатели эффективности моделей, но важно, чтобы и тестовая и обучающая выборки имели достаточное количество точек. Поэтому поделим датасет пополам, хотя на практике такая пропорция не используется:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Создадим и обучим на обучающей выборке простую модель логистической регрессии::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Логистическая регрессия, наряду со многими другими моделями классификации может работать как точечный предиктор (то есть выдавать для входного объекта наиболее вероятный класс), а может - как вероятностный (то есть для данного объекта выдавать оценки вероятности принадлежности к каждому классу, который присутствует в обучающей выборке). Сейчас мы поработаем как раз с этими вероятностями. Получить их очень легко, воспользуемся специальным методом:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_proba = model.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Мы получили матрицу вероятностей:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "array([[4.02731514e-03, 9.95972685e-01],\n",
        "       [2.00515726e-03, 9.97994843e-01],\n",
        "       ...\n",
        "       [2.84137092e-01, 7.15862908e-01],\n",
        "       [9.69157402e-01, 3.08425976e-02]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В этой матрице количество строк совпадает с количеством объектов, которые мы передали методу (в данном случае мы передали всю тестовую выборку). Для каждого объекта в матрице указано два значения - вероятности его отнесения, по мнению модели, соответственно, к отрицательному и положительному классу. Так как задача у нас бинарная, можно заметить, что эти два числа всегда дают в сумме единицу. В общем случае, для множественной классификации, это не обязательно выполняется. Но в даннос случае нам дальше вообще понадобится только второй столбец этой матрицы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для построения кривой ROC используем встроенную в _sklearn_ функцию _roc\\_curve_, которая находится в пакете _metrics_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Данная функция возвражает три массива: значения метрики FPR (false positive rate), TPR (true positive rate) и значение порога. Фактически, данная функция берет определенное количество значений порога (в промежутке от 0 до 1), применяет данный порог для точной классификации, исходя из переданной ей матрицы вероятностей, и вычисляет при данном значении порога две упомянутые метрики."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Значения порога нас пока не очень интересуют, а первые два массива мы используем для построения графика - того самомго ROC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Здесь мы значала рисуем прямую между точками (0,0) и (1, 1) - это референсная линия, которая представляет условный тривиальный классификатор. Именно с ней мы будем сравнивать получившуюся кривую, А она должна распологаться примено так:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/koroteevmv/ML_course/blob/main/ML4.2%20threshold/img/ml42-1.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Из графика мы видим, что кривая находится выше прямой, что свидетельствует о том, что классификатор работает лучше, чем случайное предсказание. Но можно заметить, что при разных значениях порога (зеленые точки на графике) модель имеет значительно различающиеся характеристики. И только одна точка на этом графике характеризует поведение модели при \"дефолтном\" значении порога - то, что мы обычно не задумываясь получаем методом _predict_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Но анализ графика может нам дать только примерное представление о том, насколько хороша модель. Особенно сейчас, когда нам не с чем ее сравнить. Боле четкую оценку даст метрика ROC-AUC, измеряющая площадь под графиком данной кривой. Эту метрику также легко получить:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "roc_auc_score(y_test, y_pred_proba[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В данном случае, мы имеем значение примерно в 90,3%, что можно интерпретировать как общее качество модели вне зависимости от выбранного порога."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Давайте по аналогии построим график PR-кривой. Из лекции мы знаем, что он строится по аналогичному признаку, но в других координатах. Конечно, библиотека _sklearn_ и здесь позволяет пользоваться готовыми функциями:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обратите внимание, что в этих координатах (precision и recall) эффективность тривиального классификатора уже не так примитивна и ависит от соотношения классов в обучающей выборке. Мы уже говорили об этом на лекции. Вот как просто можно его изобразить:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "no_skill = len(y[y==1]) / len(y)\n",
        "plt.plot([0, 1], [no_skill, no_skill], linestyle='--')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "А теперь можно вывести на график и саму кривую PR:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(recall, precision, marker='.')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/koroteevmv/ML_course/blob/main/ML4.2%20threshold/img/ml42-2.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Точно также, как и с ROC можно вычислить соответствующую численную метрику - площадь под графиком PR-кривой - PR-AUC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auc(recall, precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Эта метрика численно чуть ниже - порядка 89,8%. Еще это число называют средней точностью модели - average precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Полезно посмотреть, как полученные данные соотносятся с уже знакомыми нам характеристиками классификации. Давайте построим отчет о классификации по данной модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision    recall  f1-score   support\n",
        "\n",
        "           0       0.83      0.82      0.83       240\n",
        "           1       0.84      0.85      0.84       260\n",
        "\n",
        "    accuracy                           0.83       500\n",
        "   macro avg       0.83      0.83      0.83       500\n",
        "weighted avg       0.83      0.83      0.83       500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Важно понимать, что данный отчет характеризует поведение модели только в одной точке - при значении порога, равном по умолчанию 0,5. Кривые же показывают, как модель будет работать при все возможных значениях порога."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Давайте для сравнения попробуем обучить на этих же данных другую модель. Например, метод ближайших сосдей. Вы можете выбрать любую другую модель (но обратите внимание, что не все модели имеют метод _redict\\_proba_, а нам он обязательно понадоится. Почему так, читайте в документации к моделям):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = KNeighborsClassifier(n_neighbors=250).fit(X_train, y_train)\n",
        "y_pred2_proba = model2.predict_proba(X_test)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred2_proba[:, 1])\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/koroteevmv/ML_course/blob/main/ML4.2%20threshold/img/ml42-3.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "График будет выглядеть чуть по-другому, но в целом похоже на ROC первой модели. Поэтому для точного сравнения более полезны численные метрики:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "roc_auc_score(y_test, y_pred2_proba[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Тут явно видно, что ROC-AUC второй модели значимо хуже - 86,3%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Дизбаланс классов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Наиболее явно различия между этими двумя классификационными кривыми - ROC и PR - демонстрирует пример с большим дизбалансом классов. Давайте сгенерируем датасет, в котором объектов разных классов не примерно равное количество, как в предыдущем примере, а объектов отрицательного класса, скажем, 99%. Для этого очень удобно воспользоваться атрибутом _weights_ функции _make\\_classification_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Также разделим эту выборку на две части. Но сдесь надо быть аккуратными, поэтому сразу выведем объем классов в получившихся частях:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=4)\n",
        "\n",
        "print('Датасет: Class0=%d, Class1=%d' % (len(y[y==0]), len(y[y==1])))\n",
        "print('Обучающая: Class0=%d, Class1=%d' % (len(y_train[y_train==0]), len(y_train[y_train==1])))\n",
        "print('Тестовая: Class0=%d, Class1=%d' % (len(y_test[y_test==0]), len(y_test[y_test==1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Датасет: Class0=985, Class1=15\n",
        "Обучающая: Class0=490, Class1=10\n",
        "Тестовая: Class0=495, Class1=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Видно, что в одной половине выборки положительных объектов в два раза больше, чем в другой. Прислучайном разделении, если есть сильно миноритарные классы, может случиться и не такое. Например, мы можем случайно получить выборку, в которой какие-то классы не представлены вообще. Для предотвращения таких случаев нужно воспользоваться стратификацией:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Это агрумент следит за тем, чтобы в обоих частях выборки распределение переданного атрибута было примерно такое же, как и целом датасете. Вот какая картина получается сейчас:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Датасет: Class0=985, Class1=15\n",
        "Обучающая: Class0=492, Class1=8\n",
        "Тестовая: Class0=493, Class1=7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Распределение уже гораздо более равномерное. Для стратификации можно задавать любой массив, не обязательно значение целевой переменной, и разделение произойдет так, чтобы созранить распределение, заданное в этом массиве. Но целевую переменную здесь используют чаще всего."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Точно также, как и в предыдущем примере, обучим модель и сразу вычислим матрицу вероятностей:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred_proba = model.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сразу познакомимся с дефолтным поведением модели, построив отчет о классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      1.00      0.99       493\n",
        "           1       0.00      0.00      0.00         7\n",
        "\n",
        "    accuracy                           0.98       500\n",
        "   macro avg       0.49      0.50      0.50       500\n",
        "weighted avg       0.97      0.98      0.98       500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Здесь мы видим классическую картину обучения на неравномерной выборке. Мажоритарный класс (в данном случае - отрицательный, он у нас в большинстве) распознается очень хорошо, а миноритарный - очень плохо. В нашем случае, вообще по положительному классу все метрики нулевые. Но обратите внимание, что общая точность (accuracy) модели весьма приемлема - 98%. Дизбаланс классов \"скрывает\" в точности недостатки работы модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Построим ROC данной модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/koroteevmv/ML_course/blob/main/ML4.2%20threshold/img/ml42-4.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Мы видим. что вривая показывает не идеальное, но вполне примелемое поведение модели. Средняя точность будет, несомненно, ниже, чем в первом примере работы, но ничего катастрофического мы здесь не наблюдаем. Но давайте построим кривую PR:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba[:, 1])\n",
        "no_skill = len(y[y==1]) / len(y)\n",
        "plt.plot([0, 1], [no_skill, no_skill], linestyle='--')\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/koroteevmv/ML_course/blob/main/ML4.2%20threshold/img/ml42-5.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "И вот на этом графике уже открывается истинное поведение модели: она не очень-то отличается от тривиальной, просто чаще предсказывает самый распространенный класс. Так как метрики Precision и Recall специально были созданы для случая несбалансированных классов, именно PR-кривая дает более реалистические оценки эффективности работы моделей классификации на таких данных, где наблюдается большой дисбаланс классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Выбор значения порога по кривым"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Кривые классификации, несомненно, удобный и визуальный способ представления эффективности работы моделей машинного обучения. Но главная их ценность состоит в том, что данные, которые необходимы для их построения могут использоваться для оптимизации порога классификации. Мы уже поняли, что разные значения порога могут приводить к разному поведению моделей и, как следствие, к имзенению метрик. Значит, можно выбрать такой порог, который дает более точную классификацию?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Да, но для этого нам понадобится некоторый критерий - численное значение, которые мы хотим оптимизировать. В лекции мы уже говорили, что простые метрики - precision, recall, accuracy - не очень подходят на роль критерия оптимизации. Но мы можем использовать, например, метрику F1 (и любые метрики из F-семейства). Для этого еще раз сгенерируем датасет, сделаем чуть больше объем данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = make_classification(n_samples=10000, n_classes=2, weights=[0.99, 0.01], random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y)\n",
        "\n",
        "model = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred_proba = model.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Изобразим PR-кривую:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, r, pr_thresholds = precision_recall_curve(y_test, y_pred_proba[:, 1])\n",
        "no_skill = len(y[y==1]) / len(y)\n",
        "plt.plot([0, 1], [no_skill, no_skill], linestyle='--')\n",
        "plt.plot(r, p, marker='.')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/koroteevmv/ML_course/blob/main/ML4.2%20threshold/img/ml42-6.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "По точкам на ней мы видим, что при разных значениях порога иногда метрика precision будет больше, иногда - recall. Именно поэтому мы будем оптимизировать по метрике F1. Для этого импортируем из бибилиотеки _numpy_ функцию _argmax_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import argmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Вычислим вектор метрик F1 при всех использованных значениях порога и найдем самое большое значение среди них (вернее, его индекс):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f1 = (2 * p * r) / (p + r)\n",
        "ix = argmax(f1)\n",
        "pr_thresholds[ix]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Так как индексы всех массивов, возвращенных функцией _precision\\_recall\\_curve_ соответственны, по этому индексу получим значение порога и соответствующее ему значение метрики F1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Порог=%f, F-Score=%.3f' % (pr_thresholds[ix], f1[ix]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Порог=0.273831, F-Score=0.464"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь мы можем изобразить эту точку на графике самой кривой:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot([0, 1], [no_skill, no_skill], linestyle='--')\n",
        "plt.plot(r, p, marker='.')\n",
        "plt.scatter(r[ix], p[ix], marker='o', color='black')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/koroteevmv/ML_course/blob/main/ML4.2%20threshold/img/ml42-7.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обратите внимание, что мы использовали метрику F1 - это среднее геометрическое между Precision и Recall. При этом эти две метрики имеют равный вклад в среднее. Бывают ситуации, когда нам более приоритетна одна из этих двух метрик. Тогда следует использоваться параметрическую метрику из F-семейства. Мы можем придать в среднем разный вес, то есть больше предпочесть recall или, наоборот, precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Давайте используем данное значение порога для проведение непосредственной классификации. Раньше мы так не делали, так как всегда использовали метод _predict_, который всегда использует порог по умолчанию - 0,5. Но точечная классификация - это не что иное, как выбор положительного класса, если модель оценивает вероятность принадлежности к нему выше порога:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = (y_pred_proba[:, 1] > pr_thresholds[ix]).astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Полученный вектор значений можно использовать при построении точета о классфикации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      1.00      0.99      4920\n",
        "           1       0.81      0.31      0.45        80\n",
        "\n",
        "    accuracy                           0.99      5000\n",
        "   macro avg       0.90      0.66      0.72      5000\n",
        "weighted avg       0.99      0.99      0.99      5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "А вот для сравнения, отчет о классификации для той же модели, но при использованиии порога по умолчанию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      1.00      0.99      4920\n",
        "           1       0.93      0.16      0.28        80\n",
        "\n",
        "    accuracy                           0.99      5000\n",
        "   macro avg       0.96      0.58      0.63      5000\n",
        "weighted avg       0.99      0.99      0.98      5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Самостоятельно проведите сравнение и сделайте вывод об эффективности моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Задания для самостоятельного выполнения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Повторите анализ из лабораторной работы, но с двумерными датасетами. Изобразите графически, как изменение порога влияет на расположение границы принятия решений.\n",
        "1. Повторите анализ на реальном датасете для бинарной классификации. Проинтерпретируйте результат, сделайте вывод.\n",
        "1. В задании по оптимизации порога используйте ROC и среднее геометрическое между TPR и FPR как критерий оптимизации.\n",
        "1. При оптимизации порога по PR-кривой используйте другую F-метрику - сначала с преимуществом precision, а затем - с превалированием recall. Изобразите получившиеся пороги на графике. Проанализируйте метрики получившихся моделей.\n",
        "1. Постройте классификационные кривые для задачи множественной классификации. Проинтерпретируйте результат.\n",
        "1. Используйте для построения кривых библиотеку _yellowbrick_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Контрольные вопросы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Какие модели можно оценивать с помощью классификационных кривых (ROC и PR) и почему именно их?\n",
        "1. В каких случаях лучше использовать PR-кривую, а в каких - ROC и почему?\n",
        "1. Какие виды усреднения вы знаете (micro, macro) и в чем особенности их применения?\n",
        "1. Как вычисляются метрики для построения кривых в задачах множественной классификации?\n",
        "1. Почему при построении кривых с помощью _yellowbrick_ на графике отображаются сразу несколько кривых и что они значат?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Дополнительные задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. На реальном датасете для бинарной классификации используйте кривые для сравнения нескольких видов моделей между собой (изобразите кривые разных моделей на одном графике). Сделайте вывод о том, какая модель будет лучше работать с учетом оптимизации порога.\n",
        "1. Повторите предыдущее задание, но для задачи множественной классификации. Выберите два датасета: один с относительно равным распределением классов, а второй - с близким к экспоненциальному, с большим неравенством классов. Продемонтрируйте разницу в поведении моделей на разных кривых."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
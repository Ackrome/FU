{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import wbdata\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sympy import *\n",
    "import time as dt\n",
    "import warnings\n",
    "from IPython.display import Math,Latex\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.api import *\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures,StandardScaler,MinMaxScaler\n",
    "\n",
    "from scipy.stats import jarque_bera, kstest, kstwobign\n",
    "\n",
    "from country_dict import *\n",
    "from matplobblib.econometrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=18\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 21 Nov 2024</td> <th>  Prob (F-statistic):</th>  <td>0.00123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:01:06</td>     <th>  Log-Likelihood:    </th> <td> -29.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    18</td>      <th>  AIC:               </th> <td>   66.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    14</td>      <th>  BIC:               </th> <td>   69.70</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   69.5320</td> <td>   11.088</td> <td>    6.271</td> <td> 0.000</td> <td>   45.750</td> <td>   93.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>    <td>   -0.0749</td> <td>    0.023</td> <td>   -3.278</td> <td> 0.005</td> <td>   -0.124</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>   -0.3492</td> <td>    0.093</td> <td>   -3.740</td> <td> 0.002</td> <td>   -0.550</td> <td>   -0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>    <td>   -0.0492</td> <td>    0.022</td> <td>   -2.205</td> <td> 0.045</td> <td>   -0.097</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.180</td> <th>  Durbin-Watson:     </th> <td>   2.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.914</td> <th>  Jarque-Bera (JB):  </th> <td>   0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.044</td> <th>  Prob(JB):          </th> <td>   0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.819</td> <th>  Cond. No.          </th> <td>6.26e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.26e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        Y         & \\textbf{  R-squared:         } &     0.666   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.594   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     9.294   \\\\\n",
       "\\textbf{Date:}             & Thu, 21 Nov 2024 & \\textbf{  Prob (F-statistic):} &  0.00123    \\\\\n",
       "\\textbf{Time:}             &     15:01:06     & \\textbf{  Log-Likelihood:    } &   -29.069   \\\\\n",
       "\\textbf{No. Observations:} &          18      & \\textbf{  AIC:               } &     66.14   \\\\\n",
       "\\textbf{Df Residuals:}     &          14      & \\textbf{  BIC:               } &     69.70   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      69.5320  &       11.088     &     6.271  &         0.000        &       45.750    &       93.314     \\\\\n",
       "\\textbf{X1}    &      -0.0749  &        0.023     &    -3.278  &         0.005        &       -0.124    &       -0.026     \\\\\n",
       "\\textbf{X2}    &      -0.3492  &        0.093     &    -3.740  &         0.002        &       -0.550    &       -0.149     \\\\\n",
       "\\textbf{X3}    &      -0.0492  &        0.022     &    -2.205  &         0.045        &       -0.097    &       -0.001     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.180 & \\textbf{  Durbin-Watson:     } &    2.114  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.914 & \\textbf{  Jarque-Bera (JB):  } &    0.030  \\\\\n",
       "\\textbf{Skew:}          & -0.044 & \\textbf{  Prob(JB):          } &    0.985  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.819 & \\textbf{  Cond. No.          } & 6.26e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 6.26e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.666\n",
       "Model:                            OLS   Adj. R-squared:                  0.594\n",
       "Method:                 Least Squares   F-statistic:                     9.294\n",
       "Date:                Thu, 21 Nov 2024   Prob (F-statistic):            0.00123\n",
       "Time:                        15:01:06   Log-Likelihood:                -29.069\n",
       "No. Observations:                  18   AIC:                             66.14\n",
       "Df Residuals:                      14   BIC:                             69.70\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         69.5320     11.088      6.271      0.000      45.750      93.314\n",
       "X1            -0.0749      0.023     -3.278      0.005      -0.124      -0.026\n",
       "X2            -0.3492      0.093     -3.740      0.002      -0.550      -0.149\n",
       "X3            -0.0492      0.022     -2.205      0.045      -0.097      -0.001\n",
       "==============================================================================\n",
       "Omnibus:                        0.180   Durbin-Watson:                   2.114\n",
       "Prob(Omnibus):                  0.914   Jarque-Bera (JB):                0.030\n",
       "Skew:                          -0.044   Prob(JB):                        0.985\n",
       "Kurtosis:                       2.819   Cond. No.                     6.26e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.26e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('21 ноября.xlsx')\n",
    "Y = df[['Y']]\n",
    "df = df[['X1','X2','X3']]\n",
    "df = add_constant(df)\n",
    "model = OLS(Y,df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>1.137075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>1.147613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>1.035222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>constant</td>\n",
       "      <td>1163.073118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature          VIF\n",
       "0        X1     1.137075\n",
       "1        X2     1.147613\n",
       "2        X3     1.035222\n",
       "3  constant  1163.073118"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Добавьте константу (не обязательно для VIF, но часто используется в регрессии)\n",
    "X = df.assign(constant=1)\n",
    "\n",
    "# Расчёт VIF для каждой переменной\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хи-квадрат статистика: 2.37, p-значение: 0.4999\n",
      "Мультиколлинеарность не обнаружена.\n",
      "\n",
      "Тест для переменной X1: F-статистика = 1.03, p-значение = 0.3816\n",
      "Переменная X1 не вызывает значимой мультиколлинеарности.\n",
      "\n",
      "Тест для переменной X2: F-статистика = 1.11, p-значение = 0.3561\n",
      "Переменная X2 не вызывает значимой мультиколлинеарности.\n",
      "\n",
      "Тест для переменной X3: F-статистика = 0.26, p-значение = 0.7713\n",
      "Переменная X3 не вызывает значимой мультиколлинеарности.\n",
      "\n",
      "Анализ парной корреляции:\n",
      "Корреляция между X1 и X2: -0.32\n",
      "Корреляция между X1 и X3: 0.08\n",
      "Корреляция между X2 и X3: 0.13\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "# Шаг 1. Общий тест Хи-квадрат\n",
    "def chi_square_test(corr_matrix, n_obs):\n",
    "    det = np.linalg.det(corr_matrix)\n",
    "    if det <= 0:\n",
    "        raise ValueError(\"Детерминант корреляционной матрицы отрицателен или равен нулю. Перепроверьте данные.\")\n",
    "    chi2_stat = -(n_obs - 1 - (2 / corr_matrix.shape[0])) * np.log(det)\n",
    "    df = (corr_matrix.shape[0] * (corr_matrix.shape[0] - 1)) / 2\n",
    "    p_value = chi2.sf(chi2_stat, df)\n",
    "    return chi2_stat, p_value\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "n_obs = df.shape[0]\n",
    "chi2_stat, p_value = chi_square_test(corr_matrix, n_obs)\n",
    "print(f\"Хи-квадрат статистика: {chi2_stat:.2f}, p-значение: {p_value:.4f}\")\n",
    "\n",
    "# Интерпретация\n",
    "if p_value < 0.05:\n",
    "    print(\"Обнаружена мультиколлинеарность (значимое отклонение от нуля).\")\n",
    "else:\n",
    "    print(\"Мультиколлинеарность не обнаружена.\")\n",
    "\n",
    "# Шаг 2. Индивидуальный тест для каждой переменной\n",
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "for col in df.columns:\n",
    "    y = df[col]\n",
    "    X = df.drop(columns=[col])\n",
    "    X = add_constant(X)  # Добавляем константу для регрессии\n",
    "    model = OLS(y, X).fit()\n",
    "    f_stat = model.fvalue\n",
    "    f_pval = model.f_pvalue\n",
    "    print(f\"\\nТест для переменной {col}: F-статистика = {f_stat:.2f}, p-значение = {f_pval:.4f}\")\n",
    "\n",
    "    if f_pval < 0.05:\n",
    "        print(f\"Переменная {col} находится в сильной корреляции с другими.\")\n",
    "    else:\n",
    "        print(f\"Переменная {col} не вызывает значимой мультиколлинеарности.\")\n",
    "\n",
    "# Шаг 3. Парные корреляции\n",
    "print(\"\\nАнализ парной корреляции:\")\n",
    "threshold = 0.8  # Порог для сильной корреляции\n",
    "for i in range(len(df.columns)):\n",
    "    for j in range(i + 1, len(df.columns)):\n",
    "        corr = corr_matrix.iloc[i, j]\n",
    "        print(f\"Корреляция между {df.columns[i]} и {df.columns[j]}: {corr:.2f}\")\n",
    "        if abs(corr) > threshold:\n",
    "            print(f\"⚠️ Сильная корреляция между {df.columns[i]} и {df.columns[j]}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103.57222222],\n",
       "       [109.61666667],\n",
       "       [103.91666667]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean().iloc[1:].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 4), (4, 1), (4, 1))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('21 ноября.xlsx')\n",
    "Y = df[['Y']]\n",
    "X = df[['X1','X2','X3']]\n",
    "R = np.matrix(df.corr())\n",
    "S= np.matrix((df.var(ddof=1).iloc[:].values)**0.5).reshape(-1,1)\n",
    "E = np.matrix(df.mean().iloc[:].values).reshape(-1,1)\n",
    "R.shape,S.shape,E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$№1$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$Построим~уравнение~регрессии~в~натуральном~масштабе:$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$y = 69.53201606806115-0.07491850576560796x_1-0.349244225532301x_2-0.04919109196925677x_3$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$Построим~уравнение~регрессии~в~стандартизированном~масштабе:$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$y = 0.540124965686403x_0-0.6191280435255535x_1-0.34673141765349147x_2$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$№2$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "\n",
       "Формула для частной корреляции между переменными $X_i $ и $ X_j $ с учётом всех остальных переменных выглядит следующим образом:\n",
       "\n",
       "$r_{ij \\cdot other} = -\\Omega_{ij}/\\sqrt{\\Omega_{ii} \\Omega_{jj}}$\n",
       "\n",
       "Где $ \\Omega $ — это обратная корреляционная матрица.\n",
       "\n",
       "По этой формуле посчитаем все частные корреляции:\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle r_{YX_1}=-0.658963024687056$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle r_{YX_2}=-0.706964399411687$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle r_{YX_3}=-0.507772928030178$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle r_{X_1X_2}=-0.645628016529114$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle r_{X_1X_3}=-0.247619378334348$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle r_{X_2X_3}=-0.258794280932345$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$Коэффициент~множественной~корреляции~равен:~~0.8159143374051006~$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$№3$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle Частный~коэффициент~элатичности~при~X_1~=~-0.422220587360408$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(elas\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     61\u001b[0m     display(Math(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mЧастный~коэффициент~элатичности~при~X_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m~=~\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m latex(elas[i,\u001b[38;5;241m0\u001b[39m])))\n\u001b[1;32m---> 62\u001b[0m     display(Latex(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$Этот~коэффициент~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mбольше\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mcompares[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mменьше\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m~чем~коэффициент~\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mbeta_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}~~~~~~~~~~$\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m########################################################################################################################################################################\u001b[39;00m\n\u001b[0;32m     64\u001b[0m display(Latex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$№4$\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "########################################################################################################################################################################\n",
    "#ДАННЫЕ\n",
    "########################################################################################################################################################################\n",
    "n_res=30\n",
    "R = np.matrix(df.corr())\n",
    "S= np.matrix((df.var(ddof=1).iloc[:].values)**0.5).reshape(-1,1)\n",
    "E = np.matrix(df.mean().iloc[:].values).reshape(-1,1)\n",
    "########################################################################################################################################################################\n",
    "#ПОДСЧЕТ ИСХОДЯ ИЗ ДАННЫХ\n",
    "########################################################################################################################################################################\n",
    "RX = R[1:,1:]\n",
    "r= R[1:,0]\n",
    "#1\n",
    "b = (RX**-1)@r\n",
    "beta = (RX**-1)@r\n",
    "b=np.multiply(b*S[0],1/S[1:])\n",
    "b_0=E[0]-np.sum(np.multiply(b[0:],E[1:]))\n",
    "b = np.matrix(np.vstack((np.array(b_0),np.array(b))))\n",
    "#2\n",
    "partial_corr_matrix=np.matrix([[ ((-R**-1)[i,j]/np.sqrt((R**-1)[i,i]*(R**-1)[j,j])) if i!=j else 1 for j in range((R**-1).shape[1])] for i in range((R**-1).shape[0])])\n",
    "R_mnoj=np.sqrt(r.T@(RX**-1)@r)[0,0]\n",
    "#3\n",
    "elas=np.multiply(b[1:]/E[0],E[1:])\n",
    "compares=np.where(elas>beta[:])\n",
    "#4\n",
    "fisher=np.array([[ partial_corr_matrix[i,j]**2*(n_res-E.shape[0])/((1-partial_corr_matrix[i,j]**2)*(E.shape[0]-1)) if i!=j else R_mnoj**2*(n_res-E.shape[0])/((1-R_mnoj**2)*(E.shape[0]-1)) for j in range((R).shape[1])] for i in range((R).shape[0])])[0,:].reshape(R.shape[0])\n",
    "########################################################################################################################################################################\n",
    "#ВЫВОД ИНФОРМАЦИИ\n",
    "########################################################################################################################################################################\n",
    "display(Latex('$№1$'))\n",
    "display(Latex('$Построим~уравнение~регрессии~в~натуральном~масштабе:$'))\n",
    "y1 = '$y = '+''.join(['+' + str(b[i,0])+f'x_{i}' if str(b[i,0])[0]!='-' else str(b[i,0])+f'x_{i}' for i in range(len(b))])[1:].replace('x_0','')+'$'\n",
    "display(Latex(y1))\n",
    "display(Latex('$Построим~уравнение~регрессии~в~стандартизированном~масштабе:$'))\n",
    "y = '$y = '+''.join(['+' + str(beta[i,0])+f'x_{i+1}' if str(beta[i,0])[0]!='-' else str(beta[i,0])+f'x_{i}' for i in range(len(beta))])[1:]+'$'\n",
    "display(Latex(y))\n",
    "########################################################################################################################################################################\n",
    "display(Latex('$№2$'))\n",
    "display(Latex('''\n",
    "Формула для частной корреляции между переменными $X_i $ и $ X_j $ с учётом всех остальных переменных выглядит следующим образом:\n",
    "\n",
    "$r_{ij \\cdot other} = -\\Omega_{ij}/\\sqrt{\\Omega_{ii} \\Omega_{jj}}$\n",
    "\n",
    "Где $ \\Omega $ — это обратная корреляционная матрица.\n",
    "\n",
    "По этой формуле посчитаем все частные корреляции:\n",
    "\n",
    "'''))\n",
    "for i in range(partial_corr_matrix.shape[0]):\n",
    "    for j in range(i,partial_corr_matrix.shape[1]):\n",
    "        if i!=j:\n",
    "            if i==0:\n",
    "                display(Math(('r_{Y'+f'X_{j}'+'}=') + latex(partial_corr_matrix[i,j])))\n",
    "            else:\n",
    "                display(Math(('r_{'+f'X_{i}'+f'X_{j}'+'}=') + latex(partial_corr_matrix[i,j])))\n",
    "display(Latex(f'$Коэффициент~множественной~корреляции~равен:~~{R_mnoj}~$'))\n",
    "########################################################################################################################################################################\n",
    "display(Latex('$№3$'))\n",
    "for i in range(elas.shape[0]):\n",
    "    display(Math(f'Частный~коэффициент~элатичности~при~X_{i+1}~=~'+ latex(elas[i,0])))\n",
    "    display(Latex(f'$Этот~коэффициент~{\"больше\" if compares[0] else \"меньше\"}~чем~коэффициент~'+'\\\\beta_{'+f'X_{i+1}'+'}~~~~~~~~~~$'))\n",
    "########################################################################################################################################################################\n",
    "display(Latex('$№4$'))\n",
    "for i in range(fisher.shape[0]):\n",
    "    if i==0:\n",
    "        display(Math(('F_{общий}=') + latex(fisher[i])))\n",
    "    else:\n",
    "        display(Math(('F_{'+f'X_{i}'+'}=') + latex(fisher[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel('семинар мультиколлинеарность.xlsx')\n",
    "df.columns = ['Y', 'X1','X2','X3','X4']\n",
    "df = df.iloc[0:18]\n",
    "sns.heatmap(df.corr(), cmap='rocket', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>135.2</td>\n",
       "      <td>109.5</td>\n",
       "      <td>125.2</td>\n",
       "      <td>135.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>111.4</td>\n",
       "      <td>112.2</td>\n",
       "      <td>86.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>107.4</td>\n",
       "      <td>105.3</td>\n",
       "      <td>105.1</td>\n",
       "      <td>107.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>108.1</td>\n",
       "      <td>105.1</td>\n",
       "      <td>112.4</td>\n",
       "      <td>108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>104.6</td>\n",
       "      <td>112.0</td>\n",
       "      <td>106.2</td>\n",
       "      <td>104.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>103.6</td>\n",
       "      <td>106.4</td>\n",
       "      <td>107.8</td>\n",
       "      <td>103.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>114.8</td>\n",
       "      <td>110.8</td>\n",
       "      <td>73.5</td>\n",
       "      <td>114.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>92.3</td>\n",
       "      <td>107.4</td>\n",
       "      <td>100.8</td>\n",
       "      <td>92.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.2</td>\n",
       "      <td>110.4</td>\n",
       "      <td>130.5</td>\n",
       "      <td>100.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>118.0</td>\n",
       "      <td>106.6</td>\n",
       "      <td>90.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.2</td>\n",
       "      <td>108.9</td>\n",
       "      <td>112.1</td>\n",
       "      <td>100.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.7</td>\n",
       "      <td>110.2</td>\n",
       "      <td>99.8</td>\n",
       "      <td>89.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>114.7</td>\n",
       "      <td>106.3</td>\n",
       "      <td>88.6</td>\n",
       "      <td>114.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>116.3</td>\n",
       "      <td>108.1</td>\n",
       "      <td>118.9</td>\n",
       "      <td>116.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>66.3</td>\n",
       "      <td>111.3</td>\n",
       "      <td>84.5</td>\n",
       "      <td>66.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>107.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>125.7</td>\n",
       "      <td>105.6</td>\n",
       "      <td>76.9</td>\n",
       "      <td>125.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>118.5</td>\n",
       "      <td>109.4</td>\n",
       "      <td>106.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    const     X1     X2     X3     X4\n",
       "0     1.0  135.2  109.5  125.2  135.2\n",
       "1     1.0   86.5  111.4  112.2   86.5\n",
       "2     1.0  107.4  105.3  105.1  107.4\n",
       "3     1.0  108.1  105.1  112.4  108.1\n",
       "4     1.0  104.6  112.0  106.2  104.6\n",
       "5     1.0  103.6  106.4  107.8  103.6\n",
       "6     1.0  114.8  110.8   73.5  114.8\n",
       "7     1.0   92.3  107.4  100.8   92.3\n",
       "8     1.0  100.2  110.4  130.5  100.2\n",
       "9     1.0   90.5  118.0  106.6   90.5\n",
       "10    1.0  100.2  108.9  112.1  100.2\n",
       "11    1.0   89.7  110.2   99.8   89.7\n",
       "12    1.0  114.7  106.3   88.6  114.7\n",
       "13    1.0  116.3  108.1  118.9  116.3\n",
       "14    1.0   66.3  111.3   84.5   66.3\n",
       "15    1.0  101.9  107.9  100.0  101.9\n",
       "16    1.0  125.7  105.6   76.9  125.7\n",
       "17    1.0  106.3  118.5  109.4  106.3"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = add_constant(df[['X1','X2','X3','X4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m OLS(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m]],df)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:924\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    921\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    923\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 924\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    925\u001b[0m                           hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:749\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 749\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    750\u001b[0m                           weights\u001b[38;5;241m=\u001b[39mweights, hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    751\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    752\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:203\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     96\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(endog, exog\u001b[38;5;241m=\u001b[39mexog, missing\u001b[38;5;241m=\u001b[39mmissing, hasconst\u001b[38;5;241m=\u001b[39mhasconst,\n\u001b[0;32m    676\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[1;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "model = OLS(df[['Y']],df)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для pract 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Представить наилучшую модель Филлипса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.550\n",
      "Model:                            OLS   Adj. R-squared:                  0.490\n",
      "Method:                 Least Squares   F-statistic:                     9.151\n",
      "Date:                Thu, 21 Nov 2024   Prob (F-statistic):            0.00252\n",
      "Time:                        14:44:45   Log-Likelihood:                -31.753\n",
      "No. Observations:                  18   AIC:                             69.51\n",
      "Df Residuals:                      15   BIC:                             72.18\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         68.8327     12.430      5.538      0.000      42.340      95.326\n",
      "X1            -0.0817      0.025     -3.216      0.006      -0.136      -0.028\n",
      "X2            -0.3831      0.103     -3.709      0.002      -0.603      -0.163\n",
      "==============================================================================\n",
      "Omnibus:                        0.803   Durbin-Watson:                   2.463\n",
      "Prob(Omnibus):                  0.669   Jarque-Bera (JB):                0.697\n",
      "Skew:                           0.133   Prob(JB):                        0.706\n",
      "Kurtosis:                       2.073   Cond. No.                     5.15e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.15e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=18\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "model = OLS(Y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Провести тесты на автокорреляцию (графический, метод рядов, критерий Дарбина-Уотсона, коэффициент автокорреляции) (на уровне значимости 0,05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Графический тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сильная автокорреляция на малых лагах (например, на лаге 1) может указывать на зависимость между соседними значениями остатков. Это может свидетельствовать о недоучтенных временных зависимостях, что нарушает предположение о независимости остатков в регрессионной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все значения ACF в пределах доверительных интервалов вокруг нуля предполагают, что остатковая автокорреляция отсутствует, и остатки можно считать независимыми. Доверительный интервал строится для того, чтобы учесть случайные колебания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals = model.resid\n",
    "\n",
    "graphics.tsa.plot_acf(residuals, lags=15)\n",
    "plt.title(\"Автокоррелограмма остатков\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод рядов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод рядов (или тест серий) — это статистический тест, который проверяет случайность последовательности данных, таких как остатки модели. Этот тест определяет, есть ли в последовательности какие-то паттерны, что может указывать на автокорреляцию.\n",
    "\n",
    "#### Основная идея метода рядов\n",
    "Метод рядов анализирует последовательность знаков (положительных и отрицательных) остатков модели, определяя так называемые **ряды**. Ряд — это последовательность положительных или отрицательных остатков, которая заканчивается, когда знак остатка меняется. Если остатки действительно случайны и независимы, то количество таких рядов в последовательности будет приближаться к случайному значению, определяемому теорией вероятностей.\n",
    "\n",
    "#### Как работает метод рядов?\n",
    "1. **Определение рядов**: Последовательность остатков разделяется на ряды, которые представляют собой непрерывные участки положительных или отрицательных значений. Например, если последовательность остатков выглядит так: `[+, +, -, -, +, -]`, то в ней 4 ряда (2 положительных и 2 отрицательных).\n",
    "\n",
    "2. **Подсчет числа рядов**: Подсчитывается общее количество рядов и количество положительных и отрицательных остатков.\n",
    "\n",
    "3. **Проверка случайности**: На основе числа положительных и отрицательных рядов можно вычислить ожидаемое количество рядов при условии, что остатки независимы. Затем сравнивается фактическое количество рядов с ожидаемым. \n",
    "\n",
    "4. **Выводы**: Если фактическое количество рядов значительно отличается от ожидаемого, можно предположить, что остатки не случайны и в них присутствует автокорреляция.\n",
    "\n",
    "#### Формула метода рядов\n",
    "Для последовательности длиной $ N $ с $ N_+ $ положительными и $ N_- $ отрицательными значениями, ожидаемое количество рядов $ E(R) $ вычисляется как:\n",
    "$\n",
    "E(R) = \\frac{2N_+N_-}{N} + 1\n",
    "$\n",
    "Дисперсия количества рядов $ \\text{Var}(R) $ рассчитывается как:\n",
    "$\n",
    "\\text{Var}(R) = \\frac{2N_+N_-(2N_+N_- - N)}{N^2(N - 1)}\n",
    "$\n",
    "Для проверки гипотезы используется нормализированная статистика:\n",
    "$\n",
    "Z = \\frac{R - E(R)}{\\sqrt{\\text{Var}(R)}}\n",
    "$\n",
    "Если $ |Z| $ больше критического значения нормального распределения (например, 1.96 при уровне значимости 0,05), гипотеза о случайности отклоняется.\n",
    "\n",
    "#### Интерпретация\n",
    "- Если гипотеза о случайности **отклоняется**, это говорит о наличии автокорреляции в остатках.\n",
    "- Если гипотеза о случайности **не отклоняется**, можно считать, что остатки случайны и независимы.\n",
    "\n",
    "Метод рядов помогает быстро оценить, нарушено ли предположение о случайности остатков, что может указывать на недостатки модели или необходимость ее уточнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m N \u001b[38;5;241m=\u001b[39m N_plus \u001b[38;5;241m+\u001b[39m N_minus\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Подсчет числа рядов\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msum(signs[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m signs[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ожидаемое количество рядов и дисперсия\u001b[39;00m\n\u001b[0;32m     18\u001b[0m E_R \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m N_plus \u001b[38;5;241m*\u001b[39m N_minus) \u001b[38;5;241m/\u001b[39m N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:44\u001b[0m, in \u001b[0;36mOpsMixin.__ne__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ne__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ne__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39mne)\n",
      "File \u001b[1;32mc:\\Users\\ivant\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6114\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6111\u001b[0m res_name \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_op_result_name(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m   6113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indexed_same(other):\n\u001b[1;32m-> 6114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only compare identically-labeled Series objects\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Остатки модели\n",
    "residuals = model.resid\n",
    "\n",
    "# Определение знаков\n",
    "signs = np.sign(residuals)\n",
    "\n",
    "# Подсчет положительных и отрицательных остатков\n",
    "N_plus = np.sum(signs > 0)\n",
    "N_minus = np.sum(signs < 0)\n",
    "N = N_plus + N_minus\n",
    "\n",
    "# Подсчет числа рядов\n",
    "runs = 1 + np.sum(signs[1:] != signs[:-1])\n",
    "\n",
    "# Ожидаемое количество рядов и дисперсия\n",
    "E_R = (2 * N_plus * N_minus) / N + 1\n",
    "Var_R = (2 * N_plus * N_minus * (2 * N_plus * N_minus - N)) / (N**2 * (N - 1))\n",
    "\n",
    "# Статистика Z\n",
    "Z = (runs - E_R) / np.sqrt(Var_R)\n",
    "\n",
    "# Проверка гипотезы\n",
    "alpha = 0.05\n",
    "critical_value = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "if abs(Z) > critical_value:\n",
    "    print(\"Гипотеза о случайности отклоняется, присутствует автокорреляция.\")\n",
    "else:\n",
    "    print(\"Гипотеза о случайности не отклоняется, автокорреляции нет.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критерий Дарбина-Уотсона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Критерий Дарбина-Уотсона (DW) — это статистический тест, который проверяет наличие автокорреляции первого порядка в остатках линейной регрессионной модели. Автокорреляция остатков может указывать на то, что модель не учла какую-то структуру в данных, что может снизить точность прогнозов и валидность выводов.\n",
    "\n",
    "#### Основная идея критерия Дарбина-Уотсона\n",
    "Критерий Дарбина-Уотсона определяет, насколько остатки $ e_t $ в модели связаны со значениями на предыдущих шагах $ e_{t-1} $. Если остатки модели являются случайными (без автокорреляции), их значения на разных шагах времени должны быть независимы друг от друга.\n",
    "\n",
    "#### Формула критерия Дарбина-Уотсона\n",
    "Статистика Дарбина-Уотсона $ d $ вычисляется по формуле:\n",
    "\n",
    "$\n",
    "d = \\frac{\\sum_{t=2}^{T} (e_t - e_{t-1})^2}{\\sum_{t=1}^{T} e_t^2}\n",
    "$\n",
    "\n",
    "где:\n",
    "- $ e_t $ — остаток (ошибка) модели на шаге $ t $,\n",
    "- $ T $ — общее количество наблюдений.\n",
    "\n",
    "Значение $ d $ находится в диапазоне от 0 до 4.\n",
    "\n",
    "#### Интерпретация значения $ d $\n",
    "- **Если $ d \\approx 2 $**: Это означает, что автокорреляция отсутствует, остатки случайны.\n",
    "- **Если $ d < 2 $**: Есть положительная автокорреляция, т.е. положительные остатки с большей вероятностью следуют за положительными, а отрицательные за отрицательными.\n",
    "- **Если $ d > 2 $**: Есть отрицательная автокорреляция, когда положительные и отрицательные значения чередуются чаще, чем это было бы случайно.\n",
    "\n",
    "#### Критические значения\n",
    "Для теста на значимость используется таблица критических значений $ d_L $ и $ d_U $ (нижнего и верхнего порогов), которые зависят от числа наблюдений и количества регрессоров. Интерпретация:\n",
    "- **$ d < d_L $**: Наблюдается значительная положительная автокорреляция.\n",
    "- **$ d > 4 - d_L $**: Наблюдается значительная отрицательная автокорреляция.\n",
    "- **$ d_U < d < 4 - d_U $**: Автокорреляции нет.\n",
    "- **$ d_L \\leq d \\leq d_U $** или **$ 4 - d_U \\leq d \\leq 4 - d_L $**: Результат не определен, и требуется дополнительная проверка.\n",
    "\n",
    "\n",
    "#### Пример интерпретации\n",
    "1. **Если $ dw\\_stat \\approx 2 $**: Остатки случайны, автокорреляции нет, и модель хорошо описывает данные.\n",
    "2. **Если $ dw\\_stat < 2 $**: Положительная автокорреляция. Это может означать, что модель не учла какие-то временные зависимости, и можно рассмотреть модели, учитывающие структуру автокорреляции (например, авторегрессионные модели).\n",
    "3. **Если $ dw\\_stat > 2 $**: Отрицательная автокорреляция. Это редко встречается в эконометрических данных, но может наблюдаться в некоторых временных рядах, где данные колеблются вокруг среднего значения.\n",
    "\n",
    "Критерий Дарбина-Уотсона позволяет выявить автокорреляцию в остатках модели, помогая оценить качество регрессионной модели и понять, требуется ли добавить дополнительные переменные или перестроить модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статистика Дарбина-Уотсона: 2.9288445375611776\n",
      "Отрицательная автокорреляция. Это редко встречается в эконометрических данных, но может наблюдаться в некоторых временных рядах, где данные колеблются вокруг среднего значения.\n"
     ]
    }
   ],
   "source": [
    "dw_stat = stats.durbin_watson(residuals)\n",
    "print(f\"Статистика Дарбина-Уотсона: {dw_stat}\")\n",
    "\n",
    "if dw_stat == 2:\n",
    "    print('Остатки случайны, автокорреляции нет, и модель хорошо описывает данные.')\n",
    "elif dw_stat < 2:\n",
    "    print('Положительная автокорреляция. Это может означать, что модель не учла какие-то временные зависимости, и можно рассмотреть модели, учитывающие структуру автокорреляции (например, авторегрессионные модели)')\n",
    "else:\n",
    "    print('Отрицательная автокорреляция. Это редко встречается в эконометрических данных, но может наблюдаться в некоторых временных рядах, где данные колеблются вокруг среднего значения.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коэффициент автокорреляции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициенты автокорреляции (ACF, **Autocorrelation Function**) измеряют, насколько текущие значения временного ряда зависят от его прошлых значений на разных **лагах** (шагов смещения во времени). Они показывают степень корреляции между значениями ряда на разных временных интервалах, помогая понять наличие и характер временных зависимостей.\n",
    "\n",
    "#### Как рассчитываются коэффициенты автокорреляции?\n",
    "Для временного ряда $ y_t $ коэффициент автокорреляции на лаге $ k $ ($ \\rho_k $) можно рассчитать следующим образом:\n",
    "\n",
    "$\n",
    "\\rho_k = \\frac{\\sum_{t=k+1}^{T} (y_t - \\bar{y})(y_{t-k} - \\bar{y})}{\\sum_{t=1}^{T} (y_t - \\bar{y})^2}\n",
    "$\n",
    "\n",
    "где:\n",
    "- $ y_t $ — значение временного ряда в момент времени $ t $,\n",
    "- $ \\bar{y} $ — среднее значение временного ряда,\n",
    "- $ T $ — общее количество наблюдений,\n",
    "- $ k $ — лаг.\n",
    "\n",
    "#### Интерпретация коэффициентов автокорреляции\n",
    "1. **Если $ \\rho_k \\approx 0 $** на всех лагах $ k $, это говорит о том, что значения временного ряда не зависят от предыдущих значений, и остатки случайны. Такой временной ряд не содержит автокорреляции.\n",
    "   \n",
    "2. **Если $ \\rho_k > 0 $** на малых значениях $ k $ (например, $ k = 1, 2, 3 $), то в данных присутствует **положительная автокорреляция**. Это означает, что высокие значения ряда (например, большие остатки) с большей вероятностью следуют за высокими значениями, а низкие значения — за низкими.\n",
    "\n",
    "3. **Если $ \\rho_k < 0 $** на малых значениях $ k $, это указывает на **отрицательную автокорреляцию**, когда значения временного ряда чередуются — высокое значение имеет тенденцию следовать за низким, и наоборот.\n",
    "\n",
    "4. **Постепенное затухание автокорреляции** (медленное снижение значений $ \\rho_k $) на больших лагах может свидетельствовать о наличии долгосрочной структуры или сезонности в данных.\n",
    "\n",
    "\n",
    "\n",
    "#### Как использовать ACF на практике?\n",
    "1. **Оценка случайности остатков**: Если остатки модели не автокоррелированы, большинство значений ACF для остатков будут находиться внутри доверительных интервалов.\n",
    "  \n",
    "2. **Выбор модели временного ряда**: ACF помогает определить подходящую модель для анализа временных рядов. Например:\n",
    "   - Если автокорреляция значима только на первом лаге, можно рассмотреть модель AR(1).\n",
    "   - Если автокорреляция затухает медленно, возможны сложные модели, такие как ARIMA.\n",
    "\n",
    "3. **Выявление сезонности**: Если наблюдаются пики автокорреляции через регулярные интервалы, это может указывать на сезонность.\n",
    "\n",
    "Коэффициенты автокорреляции являются важным инструментом в анализе временных рядов, позволяя глубже понять их структуру и выявить возможные временные зависимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты автокорреляции (ACF): [ 1.         -0.46442414 -0.10892655 -0.03231649  0.1095063   0.04098291\n",
      " -0.00630199 -0.11628217  0.14958133 -0.10790141  0.02844748  0.04541191\n",
      " -0.08725069  0.10172696 -0.10903842  0.11216248]\n"
     ]
    }
   ],
   "source": [
    "acf_values = tsa.acf(residuals, fft=False)\n",
    "print(\"Коэффициенты автокорреляции (ACF):\", acf_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы интерпретировать этот ряд коэффициентов автокорреляции (ACF), нужно рассмотреть значения автокорреляций на каждом лаге и понять, есть ли какие-то значимые паттерны, указывающие на структуру временных зависимостей в данных.\n",
    "\n",
    "#### Интерпретация коэффициентов автокорреляции:\n",
    "1. **Лаг 0**: Коэффициент автокорреляции равен 1.0, так как это корреляция ряда с самим собой. Это значение всегда равно 1 и используется в качестве отправной точки для сравнения следующих лагов.\n",
    "\n",
    "2. **Лаг 1**: Коэффициент автокорреляции составляет $-0.556$. Значительное отрицательное значение на первом лаге указывает на сильную **отрицательную автокорреляцию**. Это означает, что значения временного ряда имеют тенденцию чередоваться: высокие значения следуют за низкими, и наоборот. Такая структура автокорреляции характерна для данных, в которых присутствует \"чередование\" значений.\n",
    "\n",
    "3. **Лаги 2–3**: Коэффициенты $0.190$ и $-0.142$ показывают некоторую слабую положительную и отрицательную автокорреляцию на втором и третьем лагах. Это может указывать на краткосрочные паттерны или на то, что влияние автокорреляции быстро затухает после первого лага.\n",
    "\n",
    "4. **Лаги 4 и далее**: Коэффициенты на этих лагах имеют низкие значения (менее $\\pm0.05$) и близки к нулю. Это говорит о том, что на этих лагах нет значимой автокорреляции, и временная зависимость между значениями ряда после третьего лага практически отсутствует.\n",
    "\n",
    "5. **Небольшие колебания на больших лагах**: Некоторые лаги имеют небольшие значения автокорреляции, как, например, $0.049$ на шестом лаге и $0.035$ на 15-м лаге. Такие значения в пределах доверительного интервала, вероятно, не значимы и могут быть случайными. В целом, это свидетельствует о том, что временная зависимость в остатках после третьего лага отсутствует.\n",
    "\n",
    "#### Итоговая интерпретация:\n",
    "- **Основная автокорреляция** в этом ряду сосредоточена на первом лаге с сильным отрицательным значением, что указывает на чередование значений. Возможно, моделью не учтена какая-то структура, которая приводит к такой автокорреляции.\n",
    "- **Быстрое затухание автокорреляции после первых нескольких лагов** говорит о том, что зависимость между значениями временного ряда исчезает довольно быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Построить авторересионную схему 1-ого порядка AR(1) (определив коэффициент авторегрессии с помощью: Дарбина-Уотсона, методами: Кохрейна-Оркатта, Хилдрета -Лу)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод Хилдрета-Лу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод Хилдрета-Лу — это один из способов корректировки регрессионной модели, если в её остатках присутствует автокорреляция первого порядка. Этот метод, в отличие от метода Кохрейна-Оркатта, не является итерационным, а представляет собой метод подбора параметра автокорреляции $\\rho$ для корректировки модели.\n",
    "\n",
    "#### Основная идея метода Хилдрета-Лу\n",
    "Метод Хилдрета-Лу заключается в том, чтобы перебором найти такое значение параметра $\\rho$, которое минимизирует сумму квадратов преобразованных остатков. Метод используется для устранения автокорреляции первого порядка, когда она выражается через авторегрессионное уравнение:\n",
    "\n",
    "$\n",
    "e_t = \\rho e_{t-1} + u_t\n",
    "$\n",
    "\n",
    "где $ e_t $ — остаток модели в момент времени $ t $, $ \\rho $ — коэффициент автокорреляции, который подбирается, и $ u_t $ — белый шум.\n",
    "\n",
    "#### Пошаговый алгоритм метода Хилдрета-Лу\n",
    "\n",
    "1. **Выбор диапазона значений для $\\rho$**: Определяется диапазон возможных значений для $\\rho$, например от -1 до 1, с шагом (например, 0.01 или 0.05).\n",
    "\n",
    "2. **Трансформация данных**: Для каждого значения $\\rho$ в этом диапазоне преобразовывают зависимую переменную $ Y_t $ и независимые переменные $ X_t $ по следующей схеме:\n",
    "   - $ Y_t' = Y_t - \\rho Y_{t-1} $\n",
    "   - $ X_t' = X_t - \\rho X_{t-1} $\n",
    "   \n",
    "3. **Построение регрессии на преобразованных данных**: Оценивается регрессия для каждой пары $ Y_t' $ и $ X_t' $ для каждого значения $\\rho$ в выбранном диапазоне. На каждом шаге сохраняется сумма квадратов остатков.\n",
    "\n",
    "4. **Выбор оптимального $\\rho$**: Оптимальным значением $\\rho$ считается то, которое минимизирует сумму квадратов преобразованных остатков.\n",
    "\n",
    "5. **Окончательная оценка модели**: После определения оптимального значения $\\rho$ выполняется окончательная оценка регрессионной модели с применением найденного коэффициента автокорреляции.\n",
    "\n",
    "\n",
    "#### Преимущества и недостатки метода Хилдрета-Лу\n",
    "\n",
    "- **Преимущества**:\n",
    "  - Простота реализации, поскольку не требует итераций после нахождения оптимального $\\rho$.\n",
    "  - Подходит для моделей, где автокорреляция первого порядка выражена, и есть уверенность в выборе диапазона значений $\\rho$.\n",
    "\n",
    "- **Недостатки**:\n",
    "  - Зависимость от выбора диапазона $\\rho$: если диапазон выбран неправильно, решение может оказаться неэффективным.\n",
    "  - Метод предполагает линейную автокорреляцию только первого порядка и может оказаться менее точным, если данные имеют более сложные временные зависимости.\n",
    "\n",
    "#### Заключение\n",
    "Метод Хилдрета-Лу — это простой и понятный способ устранения автокорреляции первого порядка. Он подходит для моделей, где предположение об автокорреляции первого порядка обосновано. Однако точность метода сильно зависит от выбора диапазона и шага изменения $\\rho$, что может потребовать дополнительных проверок на практике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальное значение rho: -0.5099999999999996\n",
      "Модель со схемой AR(1):                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                     4108.\n",
      "Date:                Thu, 21 Nov 2024   Prob (F-statistic):           1.73e-15\n",
      "Time:                        14:24:33   Log-Likelihood:                 91.616\n",
      "No. Observations:                  32   AIC:                            -137.2\n",
      "Df Residuals:                       9   BIC:                            -103.5\n",
      "Df Model:                          22                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.7653      0.025     30.187      0.000       0.708       0.823\n",
      "x2            -0.6745      0.213     -3.161      0.012      -1.157      -0.192\n",
      "x3             1.0279      1.843      0.558      0.591      -3.141       5.196\n",
      "x4             5.2959      5.838      0.907      0.388      -7.910      18.502\n",
      "x5           -31.8435     30.055     -1.059      0.317     -99.833      36.146\n",
      "x6           -40.8330     54.508     -0.749      0.473    -164.138      82.472\n",
      "x7           319.8928    207.473      1.542      0.158    -149.443     789.229\n",
      "x8            73.6032    247.190      0.298      0.773    -485.580     632.786\n",
      "x9         -1419.6802    765.476     -1.855      0.097   -3151.306     311.946\n",
      "x10          281.2621    639.539      0.440      0.670   -1165.476    1728.000\n",
      "x11         3304.3128   1676.180      1.971      0.080    -487.470    7096.096\n",
      "x12        -1384.7247   1052.226     -1.316      0.221   -3765.025     995.576\n",
      "x13        -4439.6256   2278.146     -1.949      0.083   -9593.150     713.898\n",
      "x14         2519.3165   1214.301      2.075      0.068    -227.623    5266.256\n",
      "x15         3526.5551   1925.911      1.831      0.100    -830.157    7883.268\n",
      "x16        -2478.3573   1027.404     -2.412      0.039   -4802.507    -154.208\n",
      "x17        -1571.3907    964.299     -1.630      0.138   -3752.786     610.005\n",
      "x18         1396.4631    591.841      2.360      0.043      57.625    2735.301\n",
      "x19          305.3957    243.235      1.256      0.241    -244.839     855.631\n",
      "x20         -425.6348    197.988     -2.150      0.060    -873.515      22.246\n",
      "x21           15.7896     16.187      0.975      0.355     -20.827      52.406\n",
      "x22           54.6129     28.397      1.923      0.087      -9.625     118.851\n",
      "x23          -11.3059      5.306     -2.131      0.062     -23.308       0.697\n",
      "==============================================================================\n",
      "Omnibus:                        8.087   Durbin-Watson:                   2.464\n",
      "Prob(Omnibus):                  0.018   Jarque-Bera (JB):                9.502\n",
      "Skew:                           0.547   Prob(JB):                      0.00864\n",
      "Kurtosis:                       5.435   Cond. No.                     2.06e+12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.49e-11. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X = model.model.exog\n",
    "Y = model.model.endog\n",
    "\n",
    "# Задаем диапазон значений для rho\n",
    "rho_values = np.arange(-1, 1, 0.01)\n",
    "best_rho = None\n",
    "min_rss = float('inf')\n",
    "\n",
    "# Перебор значений rho\n",
    "for rho in rho_values:\n",
    "    # Преобразуем данные\n",
    "    Y_transformed = Y[1:] - rho * Y[:-1]\n",
    "    X_transformed = X[1:] - rho * X[:-1]\n",
    "    \n",
    "    # Строим регрессию на преобразованных данных\n",
    "    model1 = OLS(Y_transformed, X_transformed).fit()\n",
    "    rss = sum(model1.resid**2)  # Сумма квадратов остатков\n",
    "    \n",
    "    # Проверка, минимизирует ли текущее rho сумму квадратов остатков\n",
    "    if rss < min_rss:\n",
    "        min_rss = rss\n",
    "        best_rho = rho\n",
    "\n",
    "# Окончательная оценка модели с оптимальным значением rho\n",
    "Y_transformed = Y[1:] - best_rho * Y[:-1]\n",
    "X_transformed = X[1:] - best_rho * X[:-1]\n",
    "final_model = OLS(Y_transformed, X_transformed).fit()\n",
    "\n",
    "\n",
    "print(\"Оптимальное значение rho:\", best_rho)\n",
    "print(\"Модель со схемой AR(1):\", final_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальное значение $\\rho = -0.57$, полученное по методу Хилдрета-Лу, указывает на **отрицательную автокорреляцию** остатков в регрессионной модели. Это означает, что если остаток в одном периоде высок, то в следующем он, вероятно, будет низким, и наоборот. Такая чередующаяся зависимость между остатками свидетельствует о том, что в данных присутствует цикличность или \"отскакивающий\" паттерн, когда изменения в одну сторону сменяются изменениями в противоположную сторону.\n",
    "\n",
    "#### Выводы и интерпретация\n",
    "1. **Чередующаяся зависимость**: Отрицательная автокорреляция (-0.57) говорит о том, что в остатках присутствует заметная чередующаяся зависимость. Это часто встречается в данных с сезонными или цикличными паттернами, где наблюдаются регулярные изменения, которые \"сглаживают\" друг друга.\n",
    "\n",
    "2. **Эффективность корректировки**: Теперь, с учетом найденного значения $\\rho$, модель скорректирована таким образом, чтобы устранить автокорреляцию остатков первого порядка. Это должно повысить надежность коэффициентов регрессии, так как больше не будет систематической зависимости в остатках, что устраняет одну из потенциальных проблем модели.\n",
    "\n",
    "3. **Рекомендации**: Отрицательная автокорреляция в остатках может сигнализировать о недоучтенных сезонных эффектах или других временных факторах. Если это применимо к данным, стоит рассмотреть добавление переменных, отражающих сезонные или временные колебания, чтобы дополнительно повысить точность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод Кохрейна-Оркатта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод Кохрейна-Оркатта — это итерационный метод, который применяется для устранения автокорреляции первого порядка в регрессионных моделях. Он используется, когда остатки модели демонстрируют положительную автокорреляцию, и позволяет скорректировать параметры модели, чтобы сделать её более точной и избавить от автокорреляции.\n",
    "\n",
    "#### Основная идея метода Кохрейна-Оркатта\n",
    "Метод Кохрейна-Оркатта заключается в преобразовании исходной модели так, чтобы устранить автокорреляцию в остатках. Он предполагает, что остатки модели $ e_t $ связаны по схеме авторегрессии первого порядка (AR(1)):\n",
    "\n",
    "$\n",
    "e_t = \\rho e_{t-1} + u_t\n",
    "$\n",
    "\n",
    "где:\n",
    "- $ \\rho $ — коэффициент автокорреляции, который нужно оценить,\n",
    "- $ u_t $ — белый шум, который является случайным и независимым от предыдущих значений.\n",
    "\n",
    "Метод Кохрейна-Оркатта трансформирует исходные уравнения регрессии таким образом, чтобы устранить автокорреляцию остатков.\n",
    "\n",
    "#### Пошаговый алгоритм метода Кохрейна-Оркатта\n",
    "\n",
    "1. **Оценка исходной модели**: Построить исходную регрессионную модель и рассчитать коэффициент автокорреляции первого порядка $ \\rho $ с помощью, например, критерия Дарбина-Уотсона или автокоррелограммы.\n",
    "\n",
    "2. **Трансформация переменных**: Применить следующую трансформацию к каждому уравнению модели:\n",
    "   - Для зависимой переменной $ Y_t $: $ Y_t' = Y_t - \\rho Y_{t-1} $\n",
    "   - Для каждой независимой переменной $ X_t $: $ X_t' = X_t - \\rho X_{t-1} $\n",
    "   \n",
    "   В результате получается уравнение для преобразованных переменных:\n",
    "   \n",
    "   $\n",
    "   Y_t' = \\beta_0 (1 - \\rho) + \\beta_1 X_t' + \\varepsilon_t'\n",
    "   $\n",
    "\n",
    "3. **Переоценка модели**: Построить регрессионную модель на основе преобразованных переменных $ Y_t' $ и $ X_t' $ и найти новые оценки коэффициентов.\n",
    "\n",
    "4. **Итерация**: Пересчитать коэффициент автокорреляции $ \\rho $ на основе новых остатков и повторить шаги 2 и 3, пока значения коэффициентов не перестанут значительно изменяться.\n",
    "\n",
    "#### Преимущества и недостатки метода Кохрейна-Оркатта\n",
    "- **Преимущества**:\n",
    "  - Позволяет избавиться от автокорреляции первого порядка, улучшая точность модели.\n",
    "  - Метод прост в реализации и подходит для небольших наборов данных с автокорреляцией первого порядка.\n",
    "\n",
    "- **Недостатки**:\n",
    "  - Требует многократных итераций, которые могут быть ресурсоемкими.\n",
    "  - Если автокорреляция в данных не ограничивается первым порядком, метод может быть менее эффективен.\n",
    "\n",
    "#### Заключение\n",
    "Метод Кохрейна-Оркатта помогает эффективно скорректировать модель, если в данных присутствует автокорреляция первого порядка. Благодаря итеративной процедуре и трансформации переменных метод устраняет временную зависимость остатков, делая модель более корректной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициент автокорреляции rho: -0.33435889028993254\n",
      "Модель со схемой AR(1):                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                     4108.\n",
      "Date:                Thu, 21 Nov 2024   Prob (F-statistic):           1.73e-15\n",
      "Time:                        14:24:34   Log-Likelihood:                 91.616\n",
      "No. Observations:                  32   AIC:                            -137.2\n",
      "Df Residuals:                       9   BIC:                            -103.5\n",
      "Df Model:                          22                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.7653      0.025     30.187      0.000       0.708       0.823\n",
      "x2            -0.6745      0.213     -3.161      0.012      -1.157      -0.192\n",
      "x3             1.0279      1.843      0.558      0.591      -3.141       5.196\n",
      "x4             5.2959      5.838      0.907      0.388      -7.910      18.502\n",
      "x5           -31.8435     30.055     -1.059      0.317     -99.833      36.146\n",
      "x6           -40.8330     54.508     -0.749      0.473    -164.138      82.472\n",
      "x7           319.8928    207.473      1.542      0.158    -149.443     789.229\n",
      "x8            73.6032    247.190      0.298      0.773    -485.580     632.786\n",
      "x9         -1419.6802    765.476     -1.855      0.097   -3151.306     311.946\n",
      "x10          281.2621    639.539      0.440      0.670   -1165.476    1728.000\n",
      "x11         3304.3128   1676.180      1.971      0.080    -487.470    7096.096\n",
      "x12        -1384.7247   1052.226     -1.316      0.221   -3765.025     995.576\n",
      "x13        -4439.6256   2278.146     -1.949      0.083   -9593.150     713.898\n",
      "x14         2519.3165   1214.301      2.075      0.068    -227.623    5266.256\n",
      "x15         3526.5551   1925.911      1.831      0.100    -830.157    7883.268\n",
      "x16        -2478.3573   1027.404     -2.412      0.039   -4802.507    -154.208\n",
      "x17        -1571.3907    964.299     -1.630      0.138   -3752.786     610.005\n",
      "x18         1396.4631    591.841      2.360      0.043      57.625    2735.301\n",
      "x19          305.3957    243.235      1.256      0.241    -244.839     855.631\n",
      "x20         -425.6348    197.988     -2.150      0.060    -873.515      22.246\n",
      "x21           15.7896     16.187      0.975      0.355     -20.827      52.406\n",
      "x22           54.6129     28.397      1.923      0.087      -9.625     118.851\n",
      "x23          -11.3059      5.306     -2.131      0.062     -23.308       0.697\n",
      "==============================================================================\n",
      "Omnibus:                        8.087   Durbin-Watson:                   2.464\n",
      "Prob(Omnibus):                  0.018   Jarque-Bera (JB):                9.502\n",
      "Skew:                           0.547   Prob(JB):                      0.00864\n",
      "Kurtosis:                       5.435   Cond. No.                     2.06e+12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.49e-11. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "r = 1 - dw_stat/2\n",
    "\n",
    "X = model.model.exog\n",
    "Y = model.model.endog\n",
    "\n",
    "model1 = OLS(Y, X).fit()\n",
    "residuals = model1.resid\n",
    "\n",
    "# Шаг 2: Оценка коэффициента автокорреляции\n",
    "rho = np.corrcoef(residuals[1:], residuals[:-1])[0, 1]\n",
    "\n",
    "# Итерационный процесс\n",
    "for _ in range(10):  # Максимум 10 итераций, можно остановиться раньше, если разница мала\n",
    "    Y_transformed = Y[1:] - rho * Y[:-1]\n",
    "    X_transformed = X[1:] - rho * X[:-1]\n",
    "\n",
    "    # Переоценка модели на преобразованных данных\n",
    "    model1 = OLS(Y_transformed, X_transformed).fit()\n",
    "    residuals = model1.resid\n",
    "\n",
    "    # Обновляем rho и проверяем условие остановки\n",
    "    new_rho = np.corrcoef(residuals[1:], residuals[:-1])[0, 1]\n",
    "    if abs(new_rho - rho) < 1e-5:  # Условие остановки\n",
    "        break\n",
    "    rho = new_rho\n",
    "\n",
    "print(\"Коэффициент автокорреляции rho:\", rho)\n",
    "print(\"Модель со схемой AR(1):\", final_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент автокорреляции $\\rho = -0.424$, полученный по методу Кохрейна-Оркатта, также указывает на **отрицательную автокорреляцию** в остатках модели, но с меньшей величиной автокорреляции по сравнению с предыдущим результатом (-0.57 по методу Хилдрета-Лу).\n",
    "\n",
    "#### Выводы и интерпретация:\n",
    "\n",
    "1. **Отрицательная автокорреляция**: Значение $\\rho = -0.424$ подтверждает, что остатки модели имеют отрицательную автокорреляцию. Это означает, что высокие значения остатков с большой вероятностью будут следовать за низкими значениями и наоборот. Такая динамика может свидетельствовать о наличии цикличных или колеблющихся паттернов в данных.\n",
    "\n",
    "2. **Сравнение с методом Хилдрета-Лу**: Полученное значение $\\rho$ по методу Кохрейна-Оркатта ($-0.424$) несколько меньше, чем по методу Хилдрета-Лу ($-0.57$). Это может означать, что подходы к оценке автокорреляции дали немного разные результаты, что является нормальной ситуацией в эконометрике, поскольку оба метода имеют свои особенности и нюансы.\n",
    "\n",
    "3. **Корректировка модели**: В обоих случаях, с учетом автокорреляции в остатках, корректировка модели (например, с использованием авторегрессионных моделей или модели ARIMA) будет полезной для улучшения точности предсказаний. \n",
    "\n",
    "4. **Уровень автокорреляции**: Значение $\\rho = -0.424$ не слишком велико, но оно указывает на заметную автокорреляцию, которую стоит учитывать при дальнейшей обработке данных. Это значение подтверждает, что в данных есть некоторый циклический характер, но автокорреляция достаточно умеренная.\n",
    "\n",
    "\n",
    "Таким образом, коэффициент $\\rho = -0.424$ подтверждает наличие отрицательной автокорреляции в данных, и для повышения точности модели стоит рассматривать корректировки и учет этих временных зависимостей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

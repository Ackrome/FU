{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Параллельные вычисления (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы:\n",
    "* Макрушин С.В. Лекция \"Параллельные вычисления\"\n",
    "* https://nalepae.github.io/pandarallel/\n",
    "    * https://github.com/nalepae/pandarallel/blob/master/docs/examples_windows.ipynb\n",
    "    * https://github.com/nalepae/pandarallel/blob/master/docs/examples_mac_linux.ipynb\n",
    "* https://requests.readthedocs.io/en/latest/\n",
    "* https://docs.python.org/3/library/pathlib.html\n",
    "* https://realpython.com/python-pathlib/\n",
    "* https://realpython.com/python-gil/\n",
    "* https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.ThreadPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Выведите на экран слова из файла words_alpha, в которых есть две или более буквы \"e\" подряд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ff9c0b7f-2882-454b-9e60-8751ca6650b5",
       "rows": [
        [
         "48656",
         "cartonful"
        ],
        [
         "172440",
         "limniad"
        ],
        [
         "226425",
         "paretically"
        ],
        [
         "65554",
         "condenses"
        ],
        [
         "61219",
         "cobego"
        ],
        [
         "361248",
         "voluntaryist"
        ],
        [
         "237787",
         "pyrodine"
        ],
        [
         "292412",
         "sirocco"
        ],
        [
         "2633",
         "acolytus"
        ],
        [
         "320630",
         "thapsia"
        ],
        [
         "122363",
         "gashing"
        ],
        [
         "124693",
         "gibelite"
        ],
        [
         "257245",
         "pussly"
        ],
        [
         "272530",
         "richellite"
        ],
        [
         "229972",
         "pentandrous"
        ],
        [
         "269329",
         "reshovel"
        ],
        [
         "80257",
         "deltaite"
        ],
        [
         "28549",
         "bashilange"
        ],
        [
         "295931",
         "snuffs"
        ],
        [
         "151432",
         "industriousness"
        ],
        [
         "152783",
         "inirritable"
        ],
        [
         "205721",
         "nonpalatal"
        ],
        [
         "367719",
         "worthlessness"
        ],
        [
         "221487",
         "oversweated"
        ],
        [
         "143254",
         "homostylous"
        ],
        [
         "351777",
         "unspirituous"
        ],
        [
         "138429",
         "hydrargyriasis"
        ],
        [
         "162908",
         "kalinite"
        ],
        [
         "161674",
         "jokelet"
        ],
        [
         "274128",
         "ron"
        ],
        [
         "76147",
         "daemonurgist"
        ],
        [
         "135416",
         "heister"
        ],
        [
         "11523",
         "anachorism"
        ],
        [
         "226380",
         "parentdom"
        ],
        [
         "350540",
         "unscrambles"
        ],
        [
         "24795",
         "avifaunistic"
        ],
        [
         "7009",
         "airtightly"
        ],
        [
         "351906",
         "unstaggering"
        ],
        [
         "216410",
         "outcrawls"
        ],
        [
         "211073",
         "octogenarians"
        ],
        [
         "249179",
         "prerogatived"
        ],
        [
         "36975",
         "boasting"
        ],
        [
         "31263",
         "belong"
        ],
        [
         "285837",
         "sequencers"
        ],
        [
         "18019",
         "approved"
        ],
        [
         "254676",
         "pseudodermic"
        ],
        [
         "299034",
         "speedly"
        ],
        [
         "315509",
         "takeovers"
        ],
        [
         "341933",
         "unfactual"
        ],
        [
         "149907",
         "incitate"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 370103
       }
      },
      "text/plain": [
       "48656         cartonful\n",
       "172440          limniad\n",
       "226425      paretically\n",
       "65554         condenses\n",
       "61219            cobego\n",
       "              ...      \n",
       "87788          discuses\n",
       "15625        antimonies\n",
       "237530           piques\n",
       "265244         reforger\n",
       "190827    myzostomatous\n",
       "Name: 0, Length: 370103, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "words = (\n",
    "    pd.read_csv(\"data/words_alpha.txt\", header=None)[0]\n",
    "    .dropna()\n",
    "    .sample(frac=1, replace=True)\n",
    ")\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Загрузите данные о комментариях с сайта jsonplaceholder.typicode.com\n",
    "\n",
    "![](https://i.imgur.com/AwiN8y6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Получите множество уникальных почтовых доменов.\n",
    "\n",
    "![](https://i.imgur.com/ceY6guU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "from functools import partial\n",
    "import subprocess\n",
    "import sys\n",
    "from pandarallel import pandarallel\n",
    "import requests\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__При решении данных задач не подразумевается использования циклов или генераторов Python в ходе работы с пакетами `numpy` и `pandas`, если в задании не сказано обратного. Решения задач, в которых для обработки массивов `numpy` или структур `pandas` используются явные циклы (без согласования с преподавателем), могут быть признаны некорректными и не засчитаны.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"1\"></p>\n",
    "\n",
    "1\\. Напишите функцию `f`, которая принимает на вход тэг и проверяет, удовлетворяет ли тэг следующему шаблону: `[любое число]-[любое слово]-or-less`. Возьмите файл `tag_nsteps_10m.csv`, примените функцию `f` при помощи метода _серий_ `map` к столбцу `tags` и посчитайте количество тэгов, подходящих под этот шаблон. Выведите количество подходящих тегов на экран. Измерьте время выполнения кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество подходящих тегов: 288503\n",
      "CPU times: total: 6.7 s\n",
      "Wall time: 7.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def f(tag: str) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, удовлетворяет ли тэг шаблону: [любое число]-[любое слово]-or-less.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    if not isinstance(tag, str):\n",
    "        return False\n",
    "    pattern = r'^\\d+-[a-zA-Z]+-or-less$'\n",
    "    return bool(re.fullmatch(pattern, tag))\n",
    "\n",
    "df = pd.read_csv('data/tag_nsteps_10m.csv')\n",
    "matching_count = df['tags'].map(f).sum()\n",
    "\n",
    "print(f\"Количество подходящих тегов: {matching_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"2\"></p>\n",
    "\n",
    "2\\. Напишите функцию `parallel_map`, которая принимает на вход серию `s` `pd.Series` и функцию одного аргумента `f` и поэлементно применяет эту функцию к серии, распараллелив вычисления при помощи пакета `multiprocessing`. Логика работы функции `parallel_map` должна включать следующие действия:\n",
    "* разбиение исходной серии на $K$ частей, где $K$ - количество ядер вашего процессора;\n",
    "* параллельное применение функции `f` к каждой части при помощи метода _серии_ `map` c использованием нескольких подпроцессов;\n",
    "* объединение результатов работы подпроцессов в одну серию. \n",
    "\n",
    "Возьмите файл `tag_nsteps_10m.csv`, примените функцию `f` при помощи `parallel_map` к столбцу `tags` и посчитайте количество тэгов, подходящих под этот шаблон. Выведите количество подходящих тегов на экран. Измерьте время выполнения кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 06.2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 06.2.py\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "def f(tag: str) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, удовлетворяет ли тэг шаблону: [любое число]-[любое слово]-or-less.\n",
    "    \"\"\"\n",
    "    if not isinstance(tag, str):\n",
    "        return False\n",
    "    pattern = r'^\\d+-[a-zA-Z]+-or-less$'\n",
    "    return bool(re.fullmatch(pattern, tag))\n",
    "\n",
    "def _map_on_chunk(chunk: pd.Series, func: callable) -> pd.Series:\n",
    "    \"\"\"Вспомогательная функция для применения .map() к части данных.\"\"\"\n",
    "    return chunk.map(func)\n",
    "\n",
    "def parallel_map(s: pd.Series, f: callable) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Применяет функцию f к серии s, распараллеливая вычисления\n",
    "    на K процессов, где K - количество ядер CPU.\n",
    "    \"\"\"\n",
    "    cpu_cores = os.cpu_count()\n",
    "    if cpu_cores is None:\n",
    "        cpu_cores = 2\n",
    "    print(f\"Используется {cpu_cores} ядер процессора.\")\n",
    "\n",
    "    chunks = np.array_split(s, cpu_cores)\n",
    "    \n",
    "    worker_func = partial(_map_on_chunk, func=f)\n",
    "\n",
    "    with Pool(cpu_cores) as pool:\n",
    "        processed_chunks = pool.map(worker_func, chunks)\n",
    "\n",
    "    result_series = pd.concat(processed_chunks)\n",
    "    \n",
    "    return result_series\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "\n",
    "    df = pd.read_csv('\\\\'.join(__file__.split('\\\\')[:-1])+'\\\\data\\\\tag_nsteps_10m.csv')\n",
    "\n",
    "    matching_series = parallel_map(df['tags'], f)\n",
    "\n",
    "    matching_count = matching_series.sum()\n",
    "\n",
    "    print(f\"Количество подходящих тегов: {matching_count}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Время выполнения: {end_time - start_time:.4f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STDOUT ---\n",
      "Используется 16 ядер процессора.\n",
      "Количество подходящих тегов: 288503\n",
      "Время выполнения: 4.0192 секунд\n",
      "\n",
      "--- STDERR ---\n",
      "c:\\Projects\\FU\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_file(app_file):\n",
    "    \"\"\"Запускает python-скрипт и возвращает его stdout и stderr.\"\"\"\n",
    "    \n",
    "    command = [sys.executable, app_file]\n",
    "\n",
    "    process = subprocess.Popen(\n",
    "        command,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    stdout, stderr = process.communicate()\n",
    "    \n",
    "    # Печатаем результат\n",
    "    print(\"--- STDOUT ---\")\n",
    "    print(stdout)\n",
    "    \n",
    "    if stderr:\n",
    "        print(\"--- STDERR ---\")\n",
    "        print(stderr)\n",
    "\n",
    "run_file('06.2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"3\"></p>\n",
    "\n",
    "3\\. Используя пакет `pandarallel`, примените функцию `f` из задания 1 к столбцу `tags` таблицы, с которой вы работали в этом задании. Посчитайте количество тэгов, подходящих под описанный шаблон. Выведите на экран полученный результат. Измерьте время выполнения кода. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e2335f20c54431a9a2d3fed7ac8dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=625000), Label(value='0 / 625000')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество подходящих тегов: 288503\n",
      "CPU times: total: 2.19 s\n",
      "Wall time: 5.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, verbose=2)\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/tag_nsteps_10m.csv')\n",
    "\n",
    "matching_count = df['tags'].parallel_apply(f).sum()\n",
    "\n",
    "print(f\"Количество подходящих тегов: {matching_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"4\"></p>\n",
    "\n",
    "4\\. Сайт [DummyJSON](https://dummyjson.com/) позволяет получить набор данных о товарах в виде JSON. Воспользовавшись пакетом `requests`, получите данные о __50 товарах__ и создайте словарь, где ключом является название товара (title), а значением - список ссылок на изображения этого товара. При создании словаря замените символ `/` в названии на пробел.\n",
    "\n",
    "Выведите на экран количество элементов полученного словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество товаров в словаре: 50\n",
      "Время выполнения: 1.0226 секунд\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "url = \"https://dummyjson.com/products?limit=50&skip=0\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    products_dict = {}\n",
    "\n",
    "    if 'products' in data:\n",
    "        for product in data['products']:\n",
    "            title = product.get('title')\n",
    "            images = product.get('images', [])\n",
    "\n",
    "            if title and images:\n",
    "                formatted_title = title.replace('/', ' ')\n",
    "                \n",
    "                products_dict[formatted_title] = images\n",
    "    else:\n",
    "        print(\"Ошибка: Ответ API не содержит ключ 'products'.\")\n",
    "\n",
    "    print(f\"Количество товаров в словаре: {len(products_dict)}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Ошибка при запросе к API: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Ошибка при обработке JSON: отсутствует ожидаемый ключ - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Произошла непредвиденная ошибка: {e}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Время выполнения: {end_time - start_time:.4f} секунд\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"5\"></p>\n",
    "\n",
    "5\\. Напишите функцию `download_product_imgs`, которая создает папку c названием товара внутри каталога `imgs` (сам каталог `imgs` может быть создан любым удобным способом до начала работы) и сохраняет в нее изображения. Название для файла изображения извлеките из URL.\n",
    "\n",
    "Воспользовавшись этой функцией, скачайте изображения всех продуктов. Выведите на экран общее количество загруженных файлов. Для отслеживания хода выполнения кода используйте пакет `tqdm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример кода для скачивания картинки\n",
    "url = \"https://png.pngtree.com/png-vector/20201229/ourmid/pngtree-a-british-short-blue-and-white-cat-png-image_2654518.jpg\"\n",
    "img = requests.get(url).content\n",
    "with open(\"cat.jpg\", \"wb\") as fp:\n",
    "    fp.write(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_product_imgs(title, imgs):\n",
    "    '''\n",
    "    title - название товара\n",
    "    imgs - список ссылок на изображения товара\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_imgs_dir = Path(\"imgs\")\n",
    "root_imgs_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_product_imgs(title: str, img_urls: list):\n",
    "    \"\"\"\n",
    "    Создает папку для товара и скачивает в нее все изображения.\n",
    "    \n",
    "    Args:\n",
    "        title (str): Название товара, используется для имени папки.\n",
    "        img_urls (list): Список URL-адресов изображений для скачивания.\n",
    "    \"\"\"\n",
    "    product_dir = root_imgs_dir / title\n",
    "    product_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for url in img_urls:\n",
    "        try:\n",
    "            img_content = requests.get(url).content\n",
    "            \n",
    "            file_name = Path(url).name\n",
    "            \n",
    "            save_path = product_dir / file_name\n",
    "            \n",
    "            with open(save_path, \"wb\") as f:\n",
    "                f.write(img_content)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Не удалось скачать {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаю скачивание изображений...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47907b32fbca45ee8410373f9beb0c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Скачивание продуктов:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачивание завершено.\n",
      "Время выполнения: 93.6264 секунд\n",
      "Общее количество загруженных файлов: 83\n"
     ]
    }
   ],
   "source": [
    "print(\"Начинаю скачивание изображений...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for title, imgs in tqdm(products_dict.items(), desc=\"Скачивание продуктов\"):\n",
    "    download_product_imgs(title, imgs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Скачивание завершено.\")\n",
    "print(f\"Время выполнения: {end_time - start_time:.4f} секунд\")\n",
    "total_files = sum(1 for path in root_imgs_dir.rglob('*') if path.is_file())\n",
    "\n",
    "print(f\"Общее количество загруженных файлов: {total_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"6\"></p>\n",
    "\n",
    "6\\. Создайте функцию `download_product_imgs_processes` на основе функции `download_product_imgs`, добавив в нее вывод сообщения следующего вида: `Process ID: <ID текущего процесса>`. Для определения ID процесса воспользуйтесь функцией `multiprocessing.current_process()`.\n",
    "\n",
    "Решите задачу 5, распараллелив вычисления при помощи процессов. Вместо корневого каталога `imgs` используйте `imgs_processes`. Выведите на экран общее количество загруженных файлов. Измерьте время выполнения кода. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 06.6.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 06.6.py\n",
    "\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "url = \"https://dummyjson.com/products?limit=50&skip=0\"\n",
    "products_dict = {}\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if 'products' in data:\n",
    "        for product in data['products']:\n",
    "            title = product.get('title')\n",
    "            images = product.get('images', [])\n",
    "            if title and images:\n",
    "                formatted_title = title.replace('/', ' ')\n",
    "                products_dict[formatted_title] = images\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Не удалось получить данные о продуктах: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "ROOT_IMGS_DIR_PROCESSES = Path(\"imgs_processes\")\n",
    "\n",
    "def download_product_imgs_processes(args):\n",
    "    \"\"\"\n",
    "    Создает папку для товара, скачивает в нее все изображения\n",
    "    и выводит ID текущего процесса.\n",
    "    Принимает кортеж (title, img_urls) для совместимости с pool.map.\n",
    "    \"\"\"\n",
    "    title, img_urls = args\n",
    "    \n",
    "    # Выводим ID процесса\n",
    "    process_id = multiprocessing.current_process().pid\n",
    "    print(f\"Process ID: {process_id} | Скачиваю изображения для '{title}'\")\n",
    "    \n",
    "    # Создаем папку для конкретного товара\n",
    "    product_dir = ROOT_IMGS_DIR_PROCESSES / title\n",
    "    product_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for url in img_urls:\n",
    "        try:\n",
    "            img_content = requests.get(url).content\n",
    "            file_name = Path(url).name\n",
    "            save_path = product_dir / file_name\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                f.write(img_content)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Process ID: {process_id} | Не удалось скачать {url}: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Создаем корневую директорию\n",
    "    ROOT_IMGS_DIR_PROCESSES.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"Начинаю параллельное скачивание изображений с помощью процессов...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    tasks = list(products_dict.items())\n",
    "    \n",
    "    num_processes = os.cpu_count() or 2\n",
    "    print(f\"Используется {num_processes} процессов.\")\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        list(tqdm(pool.imap(download_product_imgs_processes, tasks), total=len(tasks), desc=\"Скачивание (процессы)\"))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"\\nСкачивание завершено.\")\n",
    "    print(f\"Время выполнения: {end_time - start_time:.4f} секунд\")\n",
    "\n",
    "    total_files = sum(1 for path in ROOT_IMGS_DIR_PROCESSES.rglob('*') if path.is_file())\n",
    "    print(f\"\\nОбщее количество загруженных файлов: {total_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STDOUT ---\n",
      "Начинаю параллельное скачивание изображений с помощью процессов...\n",
      "Используется 16 процессов.\n",
      "Process ID: 23612 | Скачиваю изображения для 'Essence Mascara Lash Princess'\n",
      "Process ID: 30416 | Скачиваю изображения для 'Eyeshadow Palette with Mirror'\n",
      "Process ID: 21476 | Скачиваю изображения для 'Powder Canister'\n",
      "Process ID: 2536 | Скачиваю изображения для 'Red Lipstick'\n",
      "Process ID: 10248 | Скачиваю изображения для 'Red Nail Polish'\n",
      "Process ID: 10876 | Скачиваю изображения для 'Calvin Klein CK One'\n",
      "Process ID: 36532 | Скачиваю изображения для 'Chanel Coco Noir Eau De'\n",
      "Process ID: 29308 | Скачиваю изображения для 'Dior J'adore'\n",
      "Process ID: 23676 | Скачиваю изображения для 'Dolce Shine Eau de'\n",
      "Process ID: 23668 | Скачиваю изображения для 'Gucci Bloom Eau de'\n",
      "Process ID: 33112 | Скачиваю изображения для 'Annibale Colombo Bed'\n",
      "Process ID: 40436 | Скачиваю изображения для 'Annibale Colombo Sofa'\n",
      "Process ID: 8100 | Скачиваю изображения для 'Bedside Table African Cherry'\n",
      "Process ID: 6772 | Скачиваю изображения для 'Knoll Saarinen Executive Conference Chair'\n",
      "Process ID: 13760 | Скачиваю изображения для 'Wooden Bathroom Sink With Mirror'\n",
      "Process ID: 13372 | Скачиваю изображения для 'Apple'\n",
      "Process ID: 23612 | Скачиваю изображения для 'Beef Steak'\n",
      "Process ID: 30416 | Скачиваю изображения для 'Cat Food'\n",
      "Process ID: 2536 | Скачиваю изображения для 'Chicken Meat'\n",
      "Process ID: 10248 | Скачиваю изображения для 'Cooking Oil'\n",
      "Process ID: 13372 | Скачиваю изображения для 'Cucumber'\n",
      "Process ID: 30416 | Скачиваю изображения для 'Dog Food'\n",
      "Process ID: 10248 | Скачиваю изображения для 'Eggs'\n",
      "Process ID: 21476 | Скачиваю изображения для 'Fish Steak'\n",
      "Process ID: 23676 | Скачиваю изображения для 'Green Bell Pepper'\n",
      "Process ID: 10248 | Скачиваю изображения для 'Green Chili Pepper'\n",
      "Process ID: 23668 | Скачиваю изображения для 'Honey Jar'\n",
      "Process ID: 13372 | Скачиваю изображения для 'Ice Cream'\n",
      "Process ID: 2536 | Скачиваю изображения для 'Juice'\n",
      "Process ID: 8100 | Скачиваю изображения для 'Kiwi'\n",
      "Process ID: 13760 | Скачиваю изображения для 'Lemon'\n",
      "Process ID: 40436 | Скачиваю изображения для 'Milk'\n",
      "Process ID: 21476 | Скачиваю изображения для 'Mulberry'\n",
      "Process ID: 30416 | Скачиваю изображения для 'Nescafe Coffee'\n",
      "Process ID: 23612 | Скачиваю изображения для 'Potatoes'\n",
      "Process ID: 8100 | Скачиваю изображения для 'Protein Powder'\n",
      "Process ID: 33112 | Скачиваю изображения для 'Red Onions'\n",
      "Process ID: 10876 | Скачиваю изображения для 'Rice'\n",
      "Process ID: 40436 | Скачиваю изображения для 'Soft Drinks'\n",
      "Process ID: 23676 | Скачиваю изображения для 'Strawberry'\n",
      "Process ID: 23668 | Скачиваю изображения для 'Tissue Paper Box'\n",
      "Process ID: 2536 | Скачиваю изображения для 'Water'\n",
      "Process ID: 33112 | Скачиваю изображения для 'Decoration Swing'\n",
      "Process ID: 8100 | Скачиваю изображения для 'Family Tree Photo Frame'\n",
      "Process ID: 10248 | Скачиваю изображения для 'House Showpiece Plant'\n",
      "Process ID: 36532 | Скачиваю изображения для 'Plant Pot'\n",
      "Process ID: 6772 | Скачиваю изображения для 'Table Lamp'\n",
      "Process ID: 23612 | Скачиваю изображения для 'Bamboo Spatula'\n",
      "Process ID: 29308 | Скачиваю изображения для 'Black Aluminium Cup'\n",
      "Process ID: 2536 | Скачиваю изображения для 'Black Whisk'\n",
      "\n",
      "Скачивание завершено.\n",
      "Время выполнения: 16.4157 секунд\n",
      "\n",
      "Общее количество загруженных файлов: 83\n",
      "\n",
      "--- STDERR ---\n",
      "\n",
      "Скачивание (процессы):   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Скачивание (процессы):   2%|▏         | 1/50 [00:02<01:55,  2.35s/it]\n",
      "Скачивание (процессы):   6%|▌         | 3/50 [00:04<01:00,  1.28s/it]\n",
      "Скачивание (процессы):  12%|█▏        | 6/50 [00:07<00:47,  1.08s/it]\n",
      "Скачивание (процессы):  14%|█▍        | 7/50 [00:08<00:46,  1.09s/it]\n",
      "Скачивание (процессы):  16%|█▌        | 8/50 [00:08<00:38,  1.09it/s]\n",
      "Скачивание (процессы):  56%|█████▌    | 28/50 [00:15<00:09,  2.40it/s]\n",
      "Скачивание (процессы): 100%|██████████| 50/50 [00:15<00:00,  3.24it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_file('06.6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"7\"></p>\n",
    "\n",
    "7\\. Создайте функцию `download_product_imgs_threads` на основе функции `download_product_imgs`, добавив в нее вывод сообщения следующего вида: `Process ID: <ID текущего процесса> Thread ID: <ID текущего потока>`. Для определения ID потока воспользуйтесь функцией `threading.get_ident`.\n",
    "\n",
    "Решите задачу 5, распараллелив вычисления при помощи потоков. Вместо корневого каталога `imgs` используйте `imgs_threads`. Выведите на экран общее количество загруженных файлов. Измерьте время выполнения кода. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 06.7.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 06.7.py\n",
    "\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "from multiprocessing.pool import ThreadPool \n",
    "\n",
    "url = \"https://dummyjson.com/products?limit=50&skip=0\"\n",
    "products_dict = {}\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if 'products' in data:\n",
    "        for product in data['products']:\n",
    "            title = product.get('title')\n",
    "            images = product.get('images', [])\n",
    "            if title and images:\n",
    "                formatted_title = title.replace('/', ' ')\n",
    "                products_dict[formatted_title] = images\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Не удалось получить данные о продуктах: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "ROOT_IMGS_DIR_THREADS = Path(\"imgs_threads\")\n",
    "\n",
    "def download_product_imgs_threads(args):\n",
    "    \"\"\"\n",
    "    Создает папку для товара, скачивает в нее все изображения\n",
    "    и выводит ID текущего процесса и потока.\n",
    "    Принимает кортеж (title, img_urls) для совместимости с pool.map.\n",
    "    \"\"\"\n",
    "    title, img_urls = args\n",
    "    \n",
    "    # Получаем ID процесса и потока\n",
    "    process_id = os.getpid() # os.getpid() - простой способ получить ID процесса\n",
    "    thread_id = threading.get_ident()\n",
    "    \n",
    "    # Выводим ID процесса и потока\n",
    "    print(f\"Process ID: {process_id} Thread ID: {thread_id} | Скачиваю изображения для '{title}'\")\n",
    "    \n",
    "    # Создаем папку для конкретного товара\n",
    "    product_dir = ROOT_IMGS_DIR_THREADS / title\n",
    "    product_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for url in img_urls:\n",
    "        try:\n",
    "            img_content = requests.get(url).content\n",
    "            file_name = Path(url).name\n",
    "            save_path = product_dir / file_name\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                f.write(img_content)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Process ID: {process_id} Thread ID: {thread_id} | Не удалось скачать {url}: {e}\")\n",
    "\n",
    "# --- Шаг 3: Параллельное скачивание с использованием ThreadPool ---\n",
    "\n",
    "# Создаем корневую директорию\n",
    "ROOT_IMGS_DIR_THREADS.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Начинаю параллельное скачивание изображений с помощью потоков...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Подготавливаем список задач для пула потоков\n",
    "tasks = list(products_dict.items())\n",
    "\n",
    "# Определяем количество потоков (для I/O-задач можно использовать больше потоков, чем ядер)\n",
    "num_threads = os.cpu_count() or 2\n",
    "print(f\"Используется {num_threads} потоков.\")\n",
    "\n",
    "# Создаем пул потоков и распределяем задачи\n",
    "# Интерфейс ThreadPool идентичен Pool\n",
    "with ThreadPool(processes=num_threads) as pool:\n",
    "    # Используем pool.imap для совместимости с tqdm\n",
    "    list(tqdm(pool.imap(download_product_imgs_threads, tasks), total=len(tasks), desc=\"Скачивание (потоки)\"))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"\\nСкачивание завершено.\")\n",
    "print(f\"Время выполнения: {end_time - start_time:.4f} секунд\")\n",
    "\n",
    "# --- Шаг 4: Подсчет общего количества загруженных файлов ---\n",
    "total_files = sum(1 for path in ROOT_IMGS_DIR_THREADS.rglob('*') if path.is_file())\n",
    "print(f\"\\nОбщее количество загруженных файлов: {total_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STDOUT ---\n",
      "Начинаю параллельное скачивание изображений с помощью потоков...\n",
      "Используется 16 потоков.\n",
      "Process ID: 34540 Thread ID: 16276 | Скачиваю изображения для 'Essence Mascara Lash Princess'Process ID: 34540 Thread ID: 42956 | Скачиваю изображения для 'Eyeshadow Palette with Mirror'Process ID: 34540 Thread ID: 37704 | Скачиваю изображения для 'Powder Canister'\n",
      "\n",
      "Process ID: 34540 Thread ID: 8888 | Скачиваю изображения для 'Red Lipstick'\n",
      "\n",
      "Process ID: 34540 Thread ID: 38036 | Скачиваю изображения для 'Red Nail Polish'\n",
      "Process ID: 34540 Thread ID: 36936 | Скачиваю изображения для 'Calvin Klein CK One'\n",
      "Process ID: 34540 Thread ID: 28800 | Скачиваю изображения для 'Chanel Coco Noir Eau De'Process ID: 34540 Thread ID: 21360 | Скачиваю изображения для 'Dior J'adore'Process ID: 34540 Thread ID: 34132 | Скачиваю изображения для 'Dolce Shine Eau de'\n",
      "Process ID: 34540 Thread ID: 27164 | Скачиваю изображения для 'Gucci Bloom Eau de'Process ID: 34540 Thread ID: 12680 | Скачиваю изображения для 'Annibale Colombo Bed'\n",
      "\n",
      "Process ID: 34540 Thread ID: 15924 | Скачиваю изображения для 'Annibale Colombo Sofa'Process ID: 34540 Thread ID: 41452 | Скачиваю изображения для 'Bedside Table African Cherry'\n",
      "Process ID: 34540 Thread ID: 9120 | Скачиваю изображения для 'Knoll Saarinen Executive Conference Chair'\n",
      "\n",
      "\n",
      "\n",
      "Process ID: 34540 Thread ID: 35824 | Скачиваю изображения для 'Wooden Bathroom Sink With Mirror'Process ID: 34540 Thread ID: 36832 | Скачиваю изображения для 'Apple'\n",
      "\n",
      "Process ID: 34540 Thread ID: 37704 | Скачиваю изображения для 'Beef Steak'\n",
      "Process ID: 34540 Thread ID: 42956 | Скачиваю изображения для 'Cat Food'\n",
      "Process ID: 34540 Thread ID: 36832 | Скачиваю изображения для 'Chicken Meat'\n",
      "Process ID: 34540 Thread ID: 38036 | Скачиваю изображения для 'Cooking Oil'\n",
      "Process ID: 34540 Thread ID: 8888 | Скачиваю изображения для 'Cucumber'\n",
      "Process ID: 34540 Thread ID: 42956 | Скачиваю изображения для 'Dog Food'\n",
      "Process ID: 34540 Thread ID: 37704 | Скачиваю изображения для 'Eggs'\n",
      "Process ID: 34540 Thread ID: 16276 | Скачиваю изображения для 'Fish Steak'\n",
      "Process ID: 34540 Thread ID: 28800 | Скачиваю изображения для 'Green Bell Pepper'\n",
      "Process ID: 34540 Thread ID: 36936 | Скачиваю изображения для 'Green Chili Pepper'\n",
      "Process ID: 34540 Thread ID: 27164 | Скачиваю изображения для 'Honey Jar'\n",
      "Process ID: 34540 Thread ID: 8888 | Скачиваю изображения для 'Ice Cream'\n",
      "Process ID: 34540 Thread ID: 38036 | Скачиваю изображения для 'Juice'\n",
      "Process ID: 34540 Thread ID: 16276 | Скачиваю изображения для 'Kiwi'\n",
      "Process ID: 34540 Thread ID: 42956 | Скачиваю изображения для 'Lemon'\n",
      "Process ID: 34540 Thread ID: 28800 | Скачиваю изображения для 'Milk'\n",
      "Process ID: 34540 Thread ID: 27164 | Скачиваю изображения для 'Mulberry'\n",
      "Process ID: 34540 Thread ID: 21360 | Скачиваю изображения для 'Nescafe Coffee'\n",
      "Process ID: 34540 Thread ID: 34132 | Скачиваю изображения для 'Potatoes'\n",
      "Process ID: 34540 Thread ID: 36936 | Скачиваю изображения для 'Protein Powder'\n",
      "Process ID: 34540 Thread ID: 16276 | Скачиваю изображения для 'Red Onions'\n",
      "Process ID: 34540 Thread ID: 35824 | Скачиваю изображения для 'Rice'\n",
      "Process ID: 34540 Thread ID: 42956 | Скачиваю изображения для 'Soft Drinks'\n",
      "Process ID: 34540 Thread ID: 12680 | Скачиваю изображения для 'Strawberry'\n",
      "Process ID: 34540 Thread ID: 28800 | Скачиваю изображения для 'Tissue Paper Box'\n",
      "Process ID: 34540 Thread ID: 41452 | Скачиваю изображения для 'Water'\n",
      "Process ID: 34540 Thread ID: 38036 | Скачиваю изображения для 'Decoration Swing'\n",
      "Process ID: 34540 Thread ID: 37704 | Скачиваю изображения для 'Family Tree Photo Frame'\n",
      "Process ID: 34540 Thread ID: 34132 | Скачиваю изображения для 'House Showpiece Plant'\n",
      "Process ID: 34540 Thread ID: 21360 | Скачиваю изображения для 'Plant Pot'\n",
      "Process ID: 34540 Thread ID: 36936 | Скачиваю изображения для 'Table Lamp'\n",
      "Process ID: 34540 Thread ID: 16276 | Скачиваю изображения для 'Bamboo Spatula'\n",
      "Process ID: 34540 Thread ID: 42956 | Скачиваю изображения для 'Black Aluminium Cup'\n",
      "Process ID: 34540 Thread ID: 37704 | Скачиваю изображения для 'Black Whisk'\n",
      "\n",
      "Скачивание завершено.\n",
      "Время выполнения: 13.0209 секунд\n",
      "\n",
      "Общее количество загруженных файлов: 83\n",
      "\n",
      "--- STDERR ---\n",
      "\n",
      "Скачивание (потоки):   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Скачивание (потоки):   2%|▏         | 1/50 [00:03<02:39,  3.25s/it]\n",
      "Скачивание (потоки):  12%|█▏        | 6/50 [00:03<00:21,  2.00it/s]\n",
      "Скачивание (потоки):  16%|█▌        | 8/50 [00:05<00:23,  1.79it/s]\n",
      "Скачивание (потоки):  22%|██▏       | 11/50 [00:05<00:15,  2.46it/s]\n",
      "Скачивание (потоки):  24%|██▍       | 12/50 [00:09<00:33,  1.14it/s]\n",
      "Скачивание (потоки):  28%|██▊       | 14/50 [00:09<00:24,  1.47it/s]\n",
      "Скачивание (потоки):  56%|█████▌    | 28/50 [00:10<00:05,  4.18it/s]\n",
      "Скачивание (потоки):  90%|█████████ | 45/50 [00:13<00:00,  5.83it/s]\n",
      "Скачивание (потоки): 100%|██████████| 50/50 [00:13<00:00,  3.84it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_file('06.7.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"8\"></p>\n",
    "\n",
    "8\\. Напишите функцию `create_2d_list`, которая создает матрицу размера `m` на `n` (__в виде списка списков__) вещественных чисел из стандартного нормального распределения. Напишите функцию `sum_by_chunk`, которая принимает на вход несколько строк этой матрицы (тоже в виде списка списков) и находит сумму элементов. \n",
    "\n",
    "Используя данную функцию, решите задачу поиска суммы по всей матрице тремя способами:\n",
    "* передав в функцию `sum_by_chunk` всю матрицу целиком;\n",
    "* распараллелив вычисления при помощи процессов по следующему принципу: матрица разбивается на части (например, по 1тыс. строк); процессы независимо друг от друга обрабатывают эти части; после завершения работы всех процессов результаты агрегируются для получения результата для всей матрицы;\n",
    "* распараллелив вычисления при помощи потоков аналогичным способом.\n",
    "\n",
    "Для демонстрации результата создайте матрицу достаточно большого размера (не менее 100 тыс. строк), выведите на экран результаты работы трех вариантов решения и измерьте время выполнения каждого из них.\n",
    "\n",
    "В данном задании разрешается использовать пакет `numpy` только для создания матрицы. В этом случае необходимо преобразовать ее к списку списков до начала работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 06.8.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 06.8.py\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# --- Шаг 1: Определение функций ---\n",
    "\n",
    "def create_2d_list(m: int, n: int) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    Создает матрицу m x n в виде списка списков,\n",
    "    заполненную числами из стандартного нормального распределения.\n",
    "    \"\"\"\n",
    "    # Используем numpy для быстрой генерации, затем конвертируем в list of lists\n",
    "    return np.random.randn(m, n).tolist()\n",
    "\n",
    "def sum_by_chunk(chunk: list[list[float]]) -> float:\n",
    "    \"\"\"\n",
    "    Принимает часть матрицы (список списков) и возвращает сумму ее элементов.\n",
    "    Использует стандартные средства Python, без numpy.\n",
    "    \"\"\"\n",
    "    # Используем генераторное выражение для эффективности и краткости\n",
    "    return sum(item for row in chunk for item in row)\n",
    "\n",
    "# --- Шаг 2: Основной блок выполнения ---\n",
    "\n",
    "# Обязательная конструкция для использования multiprocessing\n",
    "if __name__ == '__main__':\n",
    "    # Задаем параметры\n",
    "    M = 200_000  # Количество строк\n",
    "    N = 100      # Количество столбцов\n",
    "    CHUNK_SIZE = 1000 # Размер одной части для параллельной обработки\n",
    "\n",
    "    print(f\"Создается матрица {M}x{N} в виде списка списков...\")\n",
    "    matrix = create_2d_list(M, N)\n",
    "    print(\"Матрица создана.\\n\")\n",
    "\n",
    "    # --- 1. Последовательное выполнение ---\n",
    "    print(\"--- 1. Последовательное выполнение ---\")\n",
    "    start_time_seq = time.time()\n",
    "    \n",
    "    total_sum_seq = sum_by_chunk(matrix)\n",
    "    \n",
    "    end_time_seq = time.time()\n",
    "    print(f\"Сумма элементов: {total_sum_seq:.4f}\")\n",
    "    print(f\"Время выполнения: {end_time_seq - start_time_seq:.4f} секунд\\n\")\n",
    "\n",
    "    # --- 2. Параллельное выполнение с процессами ---\n",
    "    print(\"--- 2. Параллельное выполнение с процессами ---\")\n",
    "    start_time_proc = time.time()\n",
    "    \n",
    "    # Разбиваем матрицу на части\n",
    "    chunks = [matrix[i:i + CHUNK_SIZE] for i in range(0, M, CHUNK_SIZE)]\n",
    "    \n",
    "    num_processes = os.cpu_count() or 2\n",
    "    print(f\"Используется {num_processes} процессов...\")\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        # Распределяем chunks по процессам и применяем функцию sum_by_chunk\n",
    "        results_proc = pool.map(sum_by_chunk, chunks)\n",
    "    \n",
    "    # Агрегируем результаты\n",
    "    total_sum_proc = sum(results_proc)\n",
    "    \n",
    "    end_time_proc = time.time()\n",
    "    print(f\"Сумма элементов: {total_sum_proc:.4f}\")\n",
    "    print(f\"Время выполнения: {end_time_proc - start_time_proc:.4f} секунд\\n\")\n",
    "\n",
    "    # --- 3. Параллельное выполнение с потоками ---\n",
    "    print(\"--- 3. Параллельное выполнение с потоками ---\")\n",
    "    start_time_thread = time.time()\n",
    "    \n",
    "    # chunks у нас уже есть из предыдущего шага\n",
    "    num_threads = os.cpu_count() or 2\n",
    "    print(f\"Используется {num_threads} потоков...\")\n",
    "    \n",
    "    with ThreadPool(processes=num_threads) as pool:\n",
    "        # Распределяем chunks по потокам\n",
    "        results_thread = pool.map(sum_by_chunk, chunks)\n",
    "        \n",
    "    # Агрегируем результаты\n",
    "    total_sum_thread = sum(results_thread)\n",
    "    \n",
    "    end_time_thread = time.time()\n",
    "    print(f\"Сумма элементов: {total_sum_thread:.4f}\")\n",
    "    print(f\"Время выполнения: {end_time_thread - start_time_thread:.4f} секунд\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STDOUT ---\n",
      "Создается матрица 200000x100 в виде списка списков...\n",
      "Матрица создана.\n",
      "\n",
      "--- 1. Последовательное выполнение ---\n",
      "Сумма элементов: -2974.9576\n",
      "Время выполнения: 0.6711 секунд\n",
      "\n",
      "--- 2. Параллельное выполнение с процессами ---\n",
      "Используется 16 процессов...\n",
      "Сумма элементов: -2974.9576\n",
      "Время выполнения: 1.1951 секунд\n",
      "\n",
      "--- 3. Параллельное выполнение с потоками ---\n",
      "Используется 16 потоков...\n",
      "Сумма элементов: -2974.9576\n",
      "Время выполнения: 0.6519 секунд\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_file('06.8.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"9\"></p>\n",
    "\n",
    "9\\. Напишите функцию `create_2d_arr`, которая создает матрицу размера `m` на `n` (__в виде массива numpy__) вещественных чисел из стандартного нормального распределения. Напишите функцию `sum_by_chunk_np`, которая принимает на вход несколько строк этой матрицы (тоже в виде массива) и находит сумму элементов. \n",
    "\n",
    "Используя данную функцию, решите задачу поиска суммы по всей матрице тремя способами аналогично задаче 8.\n",
    "\n",
    "Для демонстрации результата создайте матрицу достаточно большого размера (не менее 100 тыс. строк), выведите на экран результаты работы трех вариантов решения и измерьте время выполнения каждого из них.\n",
    "\n",
    "В данном задании при поиска суммы не используйте встроенную функцию `sum`, вместо этого используйте возможности `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 06.9.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 06.9.py\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# --- Шаг 1: Определение функций для NumPy ---\n",
    "\n",
    "def create_2d_arr(m: int, n: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Создает матрицу m x n в виде массива numpy,\n",
    "    заполненную числами из стандартного нормального распределения.\n",
    "    \"\"\"\n",
    "    return np.random.randn(m, n)\n",
    "\n",
    "def sum_by_chunk_np(chunk: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Принимает часть матрицы (массив numpy) и возвращает сумму ее элементов,\n",
    "    используя np.sum().\n",
    "    \"\"\"\n",
    "    return np.sum(chunk)\n",
    "\n",
    "# --- Шаг 2: Основной блок выполнения ---\n",
    "\n",
    "# Обязательная конструкция для использования multiprocessing\n",
    "if __name__ == '__main__':\n",
    "    # Задаем параметры\n",
    "    M = 200_000  # Количество строк\n",
    "    N = 100      # Количество столбцов\n",
    "    CHUNK_SIZE = 1000 # Размер одной части для параллельной обработки\n",
    "\n",
    "    print(f\"Создается матрица {M}x{N} в виде массива numpy...\")\n",
    "    matrix_np = create_2d_arr(M, N)\n",
    "    print(\"Матрица создана.\\n\")\n",
    "\n",
    "    # --- 1. Последовательное выполнение (Numpy) ---\n",
    "    print(\"--- 1. Последовательное выполнение (Numpy) ---\")\n",
    "    start_time_seq = time.time()\n",
    "    \n",
    "    total_sum_seq = sum_by_chunk_np(matrix_np)\n",
    "    \n",
    "    end_time_seq = time.time()\n",
    "    print(f\"Сумма элементов: {total_sum_seq:.4f}\")\n",
    "    print(f\"Время выполнения: {end_time_seq - start_time_seq:.4f} секунд\\n\")\n",
    "\n",
    "    # --- 2. Параллельное выполнение с процессами (Numpy) ---\n",
    "    print(\"--- 2. Параллельное выполнение с процессами (Numpy) ---\")\n",
    "    start_time_proc = time.time()\n",
    "    \n",
    "    # Разбиваем массив numpy на части\n",
    "    chunks = [matrix_np[i:i + CHUNK_SIZE] for i in range(0, M, CHUNK_SIZE)]\n",
    "    \n",
    "    num_processes = os.cpu_count() or 2\n",
    "    print(f\"Используется {num_processes} процессов...\")\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        results_proc = pool.map(sum_by_chunk_np, chunks)\n",
    "    \n",
    "    total_sum_proc = sum(results_proc)\n",
    "    \n",
    "    end_time_proc = time.time()\n",
    "    print(f\"Сумма элементов: {total_sum_proc:.4f}\")\n",
    "    print(f\"Время выполнения: {end_time_proc - start_time_proc:.4f} секунд\\n\")\n",
    "\n",
    "    # --- 3. Параллельное выполнение с потоками (Numpy) ---\n",
    "    print(\"--- 3. Параллельное выполнение с потоками (Numpy) ---\")\n",
    "    start_time_thread = time.time()\n",
    "    \n",
    "    # chunks у нас уже есть\n",
    "    num_threads = os.cpu_count() or 2\n",
    "    print(f\"Используется {num_threads} потоков...\")\n",
    "    \n",
    "    with ThreadPool(processes=num_threads) as pool:\n",
    "        results_thread = pool.map(sum_by_chunk_np, chunks)\n",
    "        \n",
    "    total_sum_thread = sum(results_thread)\n",
    "    \n",
    "    end_time_thread = time.time()\n",
    "    print(f\"Сумма элементов: {total_sum_thread:.4f}\")\n",
    "    print(f\"Время выполнения: {end_time_thread - start_time_thread:.4f} секунд\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STDOUT ---\n",
      "Создается матрица 200000x100 в виде массива numpy...\n",
      "Матрица создана.\n",
      "\n",
      "--- 1. Последовательное выполнение (Numpy) ---\n",
      "Сумма элементов: -409.3581\n",
      "Время выполнения: 0.0258 секунд\n",
      "\n",
      "--- 2. Параллельное выполнение с процессами (Numpy) ---\n",
      "Используется 16 процессов...\n",
      "Сумма элементов: -409.3581\n",
      "Время выполнения: 1.0240 секунд\n",
      "\n",
      "--- 3. Параллельное выполнение с потоками (Numpy) ---\n",
      "Используется 16 потоков...\n",
      "Сумма элементов: -409.3581\n",
      "Время выполнения: 0.0134 секунд\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_file('06.9.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

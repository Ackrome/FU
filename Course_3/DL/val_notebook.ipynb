{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "727573f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# РАБОТА С ДАННЫМИ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import gdown\n",
    "from   sklearn.impute               import SimpleImputer\n",
    "import subprocess\n",
    "import shutil\n",
    "import tempfile\n",
    "import inspect # код методов preprocessing\n",
    "from category_encoders import TargetEncoder\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "\n",
    "\n",
    "# СЕТЬ\n",
    "import torch\n",
    "from   torch                        import nn\n",
    "from   torch.utils.data             import DataLoader, Dataset, TensorDataset\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from   pytorch_lightning.callbacks  import ModelCheckpoint, EarlyStopping\n",
    "from   sklearn.model_selection      import train_test_split\n",
    "from   datetime                     import datetime\n",
    "from   sklearn.preprocessing        import StandardScaler\n",
    "\n",
    "\n",
    "# ЛОГИРОВАНИЕ:\n",
    "\n",
    "# ОПИСАНИЕ\n",
    "import os\n",
    "from typing import Any, List, Optional, Union\n",
    "import torchmetrics.regression as tm\n",
    "from torchmetrics                   import MetricCollection\n",
    "import torchmetrics\n",
    "import joblib\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# MLFLOW\n",
    "from   pytorch_lightning.loggers    import MLFlowLogger\n",
    "from   mlflow.tracking              import MlflowClient\n",
    "import mlflow\n",
    "from   pyngrok                      import ngrok\n",
    "# from   google.colab                 import userdata\n",
    "\n",
    "import sys\n",
    "from IPython.display import Image\n",
    "\n",
    "from playwright.sync_api import sync_playwright\n",
    "\n",
    "def run_screenshot_script(url, output_path, width=1920, height=1480):\n",
    "\t\"\"\"\n",
    "\tДелает скриншот, запуская Playwright в изолированном подпроцессе,\n",
    "\tчтобы избежать конфликтов asyncio, не требуя отдельного файла скрипта.\n",
    "\t\"\"\"\n",
    "\tscript_code = \"\"\"\n",
    "import sys\n",
    "import time\n",
    "from playwright.sync_api import sync_playwright\n",
    "\n",
    "def take_screenshot(url, output_path, width, height):\n",
    "\t'''\n",
    "\tЗапускает браузер, переходит по URL и сохраняет скриншот.\n",
    "\t'''\n",
    "\ttry:\n",
    "\t\twith sync_playwright() as p:\n",
    "\t\t\tbrowser = p.chromium.launch()\n",
    "\t\t\tpage = browser.new_page()\n",
    "\t\t\tpage.set_viewport_size({\"width\": int(width), \"height\": int(height)})\n",
    "\t\t\tpage.goto(url)\n",
    "\t\t\ttime.sleep(5)  # Даем время на прогрузку JS\n",
    "\t\t\tpage.screenshot(path=output_path)\n",
    "\t\t\tbrowser.close()\n",
    "\t\tprint(f\"Picture succesfully saved in {output_path}\")\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error occured in Playwright subprocess: {e}\", file=sys.stderr)\n",
    "\t\tsys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tscript_url = sys.argv[1]\n",
    "\tscript_output_path = sys.argv[2]\n",
    "\tscript_width = sys.argv[3]\n",
    "\tscript_height = sys.argv[4]\n",
    "\n",
    "\ttake_screenshot(script_url, script_output_path, script_width, script_height)\n",
    "\"\"\"\n",
    "\tpython_executable = sys.executable\n",
    "\tcommand = [\n",
    "\t\tpython_executable,\n",
    "\t\t\"-c\",\n",
    "\t\tscript_code,\n",
    "\t\turl,\n",
    "\t\toutput_path,\n",
    "\t\tstr(width),\n",
    "\t\tstr(height)\n",
    "\t]\n",
    "\n",
    "\ttry:\n",
    "\t\tresult = subprocess.run(\n",
    "\t\t\tcommand,\n",
    "\t\t\tcapture_output=True,\n",
    "\t\t\ttext=True,\n",
    "\t\t\tcheck=True\n",
    "\t\t)\n",
    "\n",
    "\t\tif result.stdout:\n",
    "\t\t\tprint(result.stdout.strip())\n",
    "\n",
    "\t\tif result.stderr:\n",
    "\t\t\tprint(\"Сообщения из потока ошибок:\", result.stderr.strip(), file=sys.stderr)\n",
    "\n",
    "\texcept subprocess.CalledProcessError as e:\n",
    "\t\tprint(\"Ошибка: не удалось выполнить скрипт скриншота.\", file=sys.stderr)\n",
    "\t\tprint(f\"Код возврата: {e.returncode}\", file=sys.stderr)\n",
    "\t\tprint(f\"Stdout:\\n{e.stdout}\", file=sys.stderr)\n",
    "\t\tprint(f\"Stderr:\\n{e.stderr}\", file=sys.stderr)\n",
    "\texcept FileNotFoundError:\n",
    "\t\tprint(f\"Ошибка: не удалось найти '{python_executable}'. Убедитесь, что Python установлен и доступен.\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eca3c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://drive.google.com/file/d/1IANR8nX_HbbuCNaQ23lOVJQ6w2__H-xv/view?usp=sharing SAMPLE SUBMISSION\n",
    "# #https://drive.google.com/file/d/1xfzes_aIviHAo0KKc505MiDb5s2kfQlT/view?usp=sharing TEST\n",
    "# #https://drive.google.com/file/d/1EX_wQQwd1w-plOQvcPEVp10eeGUYFQBE/view?usp=sharing TRAIN\n",
    "# SAMPLE_SUBMISSION = '1IANR8nX_HbbuCNaQ23lOVJQ6w2__H-xv'\n",
    "# TEST              = '1xfzes_aIviHAo0KKc505MiDb5s2kfQlT'\n",
    "# TRAIN             = '1EX_wQQwd1w-plOQvcPEVp10eeGUYFQBE'\n",
    "# d = {'SAMPLE_SUBMISSION': SAMPLE_SUBMISSION,\n",
    "#      'TEST': TEST,\n",
    "#      'TRAIN': TRAIN}\n",
    "# for name,id in d.items():\n",
    "#   gdown.download(id=id, output= f'{name}.csv', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7936f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLModel(pl.LightningModule):\n",
    "    def __init__(self, model, criterion, optimizer, metrics: dict = None, hyperparameters=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hyperparameters or {})\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        metrics = metrics or {}\n",
    "\n",
    "        # --- ИСПРАВЛЕНИЕ ЗДЕСЬ ---\n",
    "        # 1. Создаем базовую коллекцию метрик.\n",
    "        base_metrics = MetricCollection(metrics)\n",
    "\n",
    "        # 2. Создаем независимые копии для train и val.\n",
    "        self.train_metrics = base_metrics.clone()\n",
    "        self.val_metrics = base_metrics.clone()\n",
    "\n",
    "    def forward(self, x): return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.train_metrics.update(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log_dict(self.train_metrics, on_step=False, on_epoch=True) # prog_bar=True можно убрать, если много метрик\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.val_metrics.update(y_hat, y)\n",
    "        self.log('val_loss', loss, on_epoch=True)\n",
    "        self.log_dict(self.val_metrics, on_step=False, on_epoch=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, _ = batch\n",
    "        return self(x)\n",
    "\n",
    "    def configure_optimizers(self): return self.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1bf40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    LightningDataModule для набора данных\n",
    "    Инкапсулирует все шаги по загрузке и обработке данных.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 y_label = 'price_per_month',\n",
    "                 data_path: str = 'TRAIN.csv',\n",
    "                 batch_size: int = 32,\n",
    "                 cols_to_drop: list = []):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder = TargetEncoder()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.cols_to_drop = cols_to_drop\n",
    "        self.y_label = y_label\n",
    "        self.setup(None)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        \"\"\"\n",
    "        Этот метод вызывается для каждого GPU/процесса.\n",
    "        Здесь мы загружаем, преобразуем и разделяем данные.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        \n",
    "        df = df.drop(columns=[col for col in self.cols_to_drop if col in df.columns], errors='ignore')\n",
    "        \n",
    "        df[self.y_label] = np.log1p(df[self.y_label])\n",
    "\n",
    "        X = df.drop(self.y_label, axis=1)\n",
    "        y = df[self.y_label]\n",
    "\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "        self.encoder.fit(X_train, y_train)\n",
    "        X_train = self.encoder.transform(X_train)\n",
    "        self.scaler.fit(X_train)\n",
    "        X_train = self.scaler.transform(X_train)\n",
    "\n",
    "        X_val = self.encoder.transform(X_val)\n",
    "        X_val = self.scaler.transform(X_val)\n",
    "        X_test = self.encoder.transform(X_test)\n",
    "        X_test = self.scaler.transform(X_test)\n",
    "        \n",
    "        self.n_inputs = X_train.shape[1]\n",
    "\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train.values, dtype=torch.float32))\n",
    "            self.val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val.values, dtype=torch.float32))\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test.values, dtype=torch.float32))\n",
    "        \n",
    "        print(\"DataModule setup complete.\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef057ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Остановлен предыдущий процесс MLflow UI.\n"
     ]
    }
   ],
   "source": [
    "if 'mlflow_process' in locals() and mlflow_process.poll() is None:\n",
    "    mlflow_process.terminate()\n",
    "    mlflow_process.wait()\n",
    "    print(\"Остановлен предыдущий процесс MLflow UI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0714d159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow UI запущен с PID (ID процесса): 6840\n",
      "http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "port = 5000\n",
    "mlflow_process = subprocess.Popen([\"mlflow\", \"ui\", \"--port\", str(port)])\n",
    "print(f\"MLflow UI запущен с PID (ID процесса): {mlflow_process.pid}\")\n",
    "mlflow_url = f\"http://localhost:{port}\"\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "print(mlflow_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2a2fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTemplate:\n",
    "    \"\"\"\n",
    "    Класс-шаблон для динамического создания модели.\n",
    "    Хранит 'тело' модели и собирает финальную архитектуру.\n",
    "    Автоматически находит размерности входа и выхода тела,\n",
    "    даже если оно начинается/заканчивается нелинейными слоями.\n",
    "    \"\"\"\n",
    "    def __init__(self, body: torch.nn.Module):\n",
    "        self.body = body\n",
    "        self.body_in_features = None\n",
    "        self.body_out_features = None\n",
    "\n",
    "        # Ищем in_features, идя по слоям с начала\n",
    "        for layer in self.body:\n",
    "            if hasattr(layer, 'in_features'):\n",
    "                self.body_in_features = layer.in_features\n",
    "                break\n",
    "\n",
    "        # Ищем out_features, идя по слоям с конца\n",
    "        for layer in reversed(self.body):\n",
    "            if hasattr(layer, 'out_features'):\n",
    "                self.body_out_features = layer.out_features\n",
    "                break\n",
    "\n",
    "        # Проверка, что мы смогли найти нужные слои\n",
    "        if self.body_in_features is None or self.body_out_features is None:\n",
    "            raise ValueError(\n",
    "                \"Не удалось автоматически определить in_features или out_features из тела модели. \"\n",
    "                \"Убедитесь, что 'тело' содержит хотя бы один слой с этими атрибутами (например, nn.Linear).\"\n",
    "            )\n",
    "\n",
    "    def build(self, n_inputs: int, n_outputs: int) -> torch.nn.Sequential:\n",
    "        \"\"\"Собирает и возвращает финальную torch-модель.\"\"\"\n",
    "        # Создаем входной слой, который соединяется с телом\n",
    "        input_layer = torch.nn.Linear(n_inputs, self.body_in_features)\n",
    "\n",
    "        # Создаем выходной слой, который соединяется с телом\n",
    "        output_layer = torch.nn.Linear(self.body_out_features, n_outputs)\n",
    "\n",
    "        return torch.nn.Sequential(\n",
    "            input_layer,\n",
    "            *self.body, # Распаковываем все слои из тела\n",
    "            output_layer\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e817c60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataModule setup complete.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Adam.__init__() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     15\u001b[39m model_body = torch.nn.Sequential(\n\u001b[32m     16\u001b[39m     torch.nn.Linear(\u001b[32m256\u001b[39m, \u001b[32m512\u001b[39m),\n\u001b[32m     17\u001b[39m     torch.nn.BatchNorm1d(\u001b[32m512\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     torch.nn.ReLU()\n\u001b[32m     30\u001b[39m )\n\u001b[32m     32\u001b[39m MODEL_KWARGS={\n\u001b[32m     33\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.01\u001b[39m\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m }\n\u001b[32m     38\u001b[39m model = PLModel(\n\u001b[32m     39\u001b[39m     ModelTemplate(model_body).build(data_module.n_inputs,\u001b[32m1\u001b[39m),\n\u001b[32m     40\u001b[39m     nn.MSELoss(),\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     42\u001b[39m     {\n\u001b[32m     43\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mMAE\u001b[39m\u001b[33m'\u001b[39m: tm.MeanAbsoluteError(),\n\u001b[32m     44\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mMSE\u001b[39m\u001b[33m'\u001b[39m: tm.MeanSquaredError()\n\u001b[32m     45\u001b[39m },\n\u001b[32m     46\u001b[39m     MODEL_KWARGS\n\u001b[32m     47\u001b[39m )\n\u001b[32m     49\u001b[39m early_stop_callback = EarlyStopping(\n\u001b[32m     50\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     51\u001b[39m     patience=\u001b[32m5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# min_delta = 1e-2\u001b[39;00m\n\u001b[32m     55\u001b[39m )\n\u001b[32m     57\u001b[39m trainer = pl.Trainer(\n\u001b[32m     58\u001b[39m     max_epochs=\u001b[32m100\u001b[39m,\n\u001b[32m     59\u001b[39m     callbacks=[early_stop_callback],\n\u001b[32m     60\u001b[39m     logger=mlflow_logger\n\u001b[32m     61\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: Adam.__init__() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "train,test,sample_submission=pd.read_csv('TRAIN.csv'),pd.read_csv('TEST.csv'),pd.read_csv('SAMPLE_SUBMISSION.csv')\n",
    "\n",
    "\n",
    "experiment_name = \" Regression with Lightning\"    \n",
    "mlflow_logger = MLFlowLogger(\n",
    "    experiment_name=experiment_name,\n",
    "    tracking_uri=\"file:./mlruns\"\n",
    ")\n",
    "    \n",
    "data_module = DataModule(\n",
    "    batch_size=32\n",
    "    )\n",
    "\n",
    "\n",
    "model_body = torch.nn.Sequential(\n",
    "    torch.nn.Linear(256, 512),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.4),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.4),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU()\n",
    ")\n",
    "\n",
    "MODEL_KWARGS={\n",
    "    'lr': 0.01\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "model = PLModel(\n",
    "    ModelTemplate(model_body).build(data_module.n_inputs,1),\n",
    "    nn.MSELoss(),\n",
    "    optim.Adam(),\n",
    "    {\n",
    "        'MAE': tm.MeanAbsoluteError(),\n",
    "        'MSE': tm.MeanSquaredError()\n",
    "},\n",
    "    MODEL_KWARGS\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min',\n",
    "    # min_delta = 1e-2\n",
    ")\n",
    "    \n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    callbacks=[early_stop_callback],\n",
    "    logger=mlflow_logger\n",
    ")\n",
    "    \n",
    "trainer.fit(model, datamodule=data_module)\n",
    "trainer.test(model, datamodule=data_module)\n",
    "\n",
    "run_id = trainer.logger.run_id\n",
    "experiment_id = trainer.logger.experiment_id\n",
    "\n",
    "run_url = f\"http://localhost:{port}/#/experiments/{experiment_id}/runs/{run_id}\"\n",
    "screenshot_path = f\"images/run_{run_url.split('/')[-1]}_metrics.png\"\n",
    "\n",
    "try:\n",
    "    run_screenshot_script(run_url+ \"/model-metrics\", screenshot_path,1920,2200)\n",
    "    display(Image(filename=screenshot_path))\n",
    "except Exception as e:\n",
    "    print(f\"Failed to generate or display the screenshot: {e}\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

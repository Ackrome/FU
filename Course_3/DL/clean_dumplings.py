import os
from pathlib import Path
from typing import List, Dict, Tuple
from multiprocessing import Pool, cpu_count

import imagehash
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
from tqdm.auto import tqdm  # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm –¥–ª—è –Ω–æ—É—Ç–±—É–∫–æ–≤

class DatasetCleaner:
    def __init__(self, root_dir: str, hash_size: int = 8, threshold: int = 0):
        self.root_dir = Path(root_dir)
        self.hash_size = hash_size
        self.threshold = threshold
        self.extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}

    def _compute_hash_and_info(self, file_path: Path) -> Tuple[str, Path, int]:
        try:
            with Image.open(file_path) as img:
                img_hash = imagehash.phash(img, hash_size=self.hash_size)
                width, height = img.size
                return str(img_hash), file_path, width * height
        except Exception:
            return None, file_path, -1

    def find_duplicates(self) -> Dict[str, List[Tuple[Path, int]]]:
        all_files = [p for p in self.root_dir.rglob('*') if p.suffix.lower() in self.extensions]
        print(f"üîç –°–∫–∞–Ω–∏—Ä—É—é {len(all_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")

        with Pool(processes=cpu_count()) as pool:
            results = list(tqdm(pool.imap(self._compute_hash_and_info, all_files), total=len(all_files)))

        hashes_dict = {}
        for h_str, path, area in results:
            if h_str:
                hashes_dict.setdefault(h_str, []).append((path, area))

        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, –≥–¥–µ –±–æ–ª—å—à–µ 1 –∫–∞—Ä—Ç–∏–Ω–∫–∏
        return {k: v for k, v in hashes_dict.items() if len(v) > 1}

    def inspect_duplicates(self, num_samples: int = 5):
        """
        –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä—ã: [–û–°–¢–ê–í–õ–Ø–ï–ú] vs [–£–î–ê–õ–Ø–ï–ú].
        """
        duplicates = self.find_duplicates()
        
        if not duplicates:
            print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ—Ç.")
            return

        print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")
        print(f"üëÄ –ü–æ–∫–∞–∑—ã–≤–∞—é –ø–µ—Ä–≤—ã–µ {num_samples} –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏...\n")

        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ N –≥—Ä—É–ø–ø –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        sample_keys = list(duplicates.keys())[:num_samples]

        for h_str in sample_keys:
            file_list = duplicates[h_str]
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –°–∞–º–æ–µ –±–æ–ª—å—à–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ -> index 0 (–û—Å—Ç–∞–≤–ª—è–µ–º)
            file_list.sort(key=lambda x: x[1], reverse=True)
            
            keep_file, keep_area = file_list[0]
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∏–∑ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
            del_file, del_area = file_list[1] 

            self._plot_comparison(keep_file, keep_area, del_file, del_area)

    def _plot_comparison(self, keep_path, keep_area, del_path, del_area):
        """–†–∏—Å—É–µ—Ç –¥–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—è–¥–æ–º"""
        try:
            fig, axes = plt.subplots(1, 2, figsize=(10, 5))
            
            # –ö–∞—Ä—Ç–∏–Ω–∫–∞, –∫–æ—Ç–æ—Ä—É—é –æ—Å—Ç–∞–≤–ª—è–µ–º
            img_keep = Image.open(keep_path)
            axes[0].imshow(img_keep)
            axes[0].set_title(f"‚úÖ KEEP (Higher Res)\n{keep_path.name}\nArea: {keep_area} px", color='green', fontweight='bold')
            axes[0].axis('off')

            # –ö–∞—Ä—Ç–∏–Ω–∫–∞, –∫–æ—Ç–æ—Ä—É—é —É–¥–∞–ª—è–µ–º
            img_del = Image.open(del_path)
            axes[1].imshow(img_del)
            axes[1].set_title(f"‚ùå DELETE (Duplicate)\n{del_path.name}\nArea: {del_area} px", color='red', fontweight='bold')
            axes[1].axis('off')

            plt.tight_layout()
            plt.show()
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã —è–≤–Ω–æ
            img_keep.close()
            img_del.close()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏: {e}")

    def delete_duplicates(self):
        """
        –†–ï–ê–õ–¨–ù–û–ï –£–î–ê–õ–ï–ù–ò–ï. –ó–∞–ø—É—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏!
        """
        duplicates = self.find_duplicates()
        deleted_count = 0
        
        for file_list in tqdm(duplicates.values(), desc="Deleting"):
            file_list.sort(key=lambda x: x[1], reverse=True)
            # –í—Å–µ –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ (–Ω—É–ª–µ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞) —É–¥–∞–ª—è–µ–º
            for rm_file, _ in file_list[1:]:
                try:
                    os.remove(rm_file)
                    deleted_count += 1
                except OSError as e:
                    print(f"Error: {e}")
        
        print(f"üî• –£–î–ê–õ–ï–ù–û —Ñ–∞–π–ª–æ–≤: {deleted_count}")

# --- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ---
# 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
cleaner = DatasetCleaner(root_dir=r'C:\Projects\FU\Course_3\DL\data\yummi-classification-fu25\train\gyoza')

# 2. –°–ú–û–¢–†–ò–ú –ì–õ–ê–ó–ê–ú–ò (–ë–µ–∑–æ–ø–∞—Å–Ω–æ)
# –ò–∑–º–µ–Ω—è–π num_samples, —á—Ç–æ–±—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –±–æ–ª—å—à–µ –ø–∞—Ä
cleaner.inspect_duplicates(num_samples=5)